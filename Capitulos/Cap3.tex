\chapter{Inferencia y Predicci\'on}
\section{Introducci\'on}
En el cap\'itulo anterior se describi\'o el modelo general de probabilidad que describe el proceso de duraciones y costos en un padecimiento cr\'onico degenerativo, por lo que el siguiente paso ser\'ia hacer inferencia sobre el mismo. El objetivo de hacer inferencia es predecir futuras observaciones en base a los datos ya observados. En este cap\'itulo se sentar\'an las bases para realizar esta inferencia.\\
\\
El primer paso para realizar inferencia es la construcci\'on de la funci\'on de verosimilitud, en este caso extendida a las variables latentes y a los par\'ametros correspondientes a sus distribuciones. Una vez que se determinaron las funciones de verosimilitud, se analizan los m\'etodos de estimaci\'on que se podr\'ian usar para la predicci\'on de futuras observaciones. De este modo se puede completar la parte te\'orica de este trabajo de investigaci\'on.
\section{Verosimilitud Extendida}
Como especificado en la secci\'on anterior, una vez que el modelo de probabilidad describe de manera precisa los datos del problema podemos empezar a hacer inferencia sobre observaciones futuras. La base sobre la que se puede hacer inferencia en base a los datos ya observados es la funci\'on de verosimilitud de la funci\'on de probabilidad.\\
\\
La funci\'on de verosimilitud, seg\'un \cite{held2014applied}, se define como
\begin{defi}
La funci\'on de verosimilitud $V(\theta)$ es la funci\'on masa o la funci\'on de densidad de los datos observados $x$, entendidos en funci\'on del par\'ametro desconocido $\theta$.
\end{defi}
En este caso las variables observables se definen en funci\'on de las variables latentes, estas a su vez se describen en funci\'on de sus par\'ametros. De esto se desprende la noci\'on de verosimilitud extendida para incluir las variables latentes. Como se especifica en \cite{pitt2002constructing}, la construcci\'on de la funci\'on de verosimilitud resulta sencilla, incluso intuitiva. Sin embargo, la estimaci\'on de los par\'ametros mediante m\'axima verosimilitud no es tan sencilla pues no tiene una soluci\'on que se pueda expresar de manera anal\'itica cerrada. Usando esta construcci\'on, se escribe una funci\'on de verosimilitud para el modelo general de probabilidad de duraciones y costos\\
\begin{eqnarray}
V(\{\theta_j\},\{\gamma_j\},\{d_j\},\{c_j\}) &=& f(d_1|\theta_1)f(c_1|d_1,\gamma_1)f(\gamma_1) \times\nonumber\\
&& \times \prod_{j=2}^{N(t)} f(d_j|\theta_j)f(\theta_j|d_{j-1})f(c_j|d_j,\gamma_j)f(\gamma_j|c_{j-1})\nonumber
\end{eqnarray}
Para poder calcular la funci\'on de verosiimilitud que permite hacer inferencia, es necesario conocer las distribuciones de las variables latentes en base a las observaciones anteriores para ambas variables observables, duraciones y costos.\\
\\Para la primera variable observable se toma en cuenta la relaci\'on 
\[f_{\theta|d}(\theta|d)\propto f_{d|\theta}(d|\theta)f(\theta)\]
y que $d|\theta \sim Gamma(d|\alpha_d,\theta)$ y $\theta \sim Gamma(\theta|\alpha_\theta,\beta_\theta)$.

\begin{eqnarray*}
f_{\theta|d}(\theta|d) &\propto& \frac{\theta^{\alpha_d}}{\Gamma(\alpha_d)}\quad d^{\alpha_d-1} e^{-\{\theta d\}} \times \frac{\beta_\theta^{\alpha_\theta}}{\Gamma(\alpha_\theta)}\quad \theta^{\alpha_\theta-1} e^{-\{-\beta_\theta \theta\}}\\
&=&\frac{\beta_\theta^{\alpha_\theta}}{\Gamma(\alpha_d)\Gamma(\alpha_\theta)} \quad d^{\alpha_d-1} \quad\theta^{\alpha_d+\alpha_\theta-1} \quad e^{\{-\theta(d+\beta_\theta)\}}\\
\\
&\propto& \theta^{\alpha_d+\alpha_\theta-1} \quad e^{\{-\theta(d+\beta_\theta)\}}\\
&\Rightarrow& \theta|d \sim Gamma(\alpha_d+\alpha_\theta,d+\beta_\theta)
\end{eqnarray*}
\\
Para la variable de duraciones, la distribuci\'on de la variable latente que depende de la observaci\'on se puede expresar de una manera anal\'itica cerrada como la distribuci\'on Gamma. An\'alogamente, para la variable de costos se vuelve a tomar en cuenta la misma relaci\'on y las distribuciones 
\[c|d,\gamma \sim Weibull(c|d,\gamma) \qquad \gamma \sim InvGamma(\gamma|\alpha_\gamma,\beta_\gamma)\]
\begin{eqnarray*}
f_{\gamma|d,c}(\gamma|d,c) &\propto& \frac{d}{\gamma^d}\quad c^{d-1} e^{\{-(\frac{c}{\gamma})^d\}} \times \frac{\beta_\gamma^{\alpha_\gamma}}{\Gamma(\alpha_\gamma)}\quad (\frac{1}{\gamma})^{\alpha_\gamma+1} \quad e^{\{-(\frac{\beta_\gamma}{\gamma})\}}\\
&=&\frac{d\beta_\gamma^{\alpha_\gamma} c^{d-1}}{\Gamma(\alpha_\gamma)}\quad (\frac{1}{\gamma})^{d+\alpha_\gamma+1}\quad e^{-((\frac{\beta_\gamma}{\gamma})+(\frac{c}{\gamma})^d)}\\
&\propto&(\frac{1}{\gamma})^{d+\alpha_\gamma+1}\quad e^{-((\frac{\beta_\gamma}{\gamma})+(\frac{c}{\gamma})^d)}
\end{eqnarray*}
\\
Para la variable de costos, la distribuci\'on de la variable latente seg\'un la observaci\'on anterior no tiene una forma anal\'itica cerrada como distribuci\'on, sin embargo, el kernel se puede simular con un slice sampler; este m\'etodo se explicar\'a con detalle en la siguiente secci\'on. \\
\\
Las distribuciones que resultan de los c\'alculos anteriores son la llave que se necesita para empezar a hacer inferencia, tomando estas distrbuciones se redefine la verosimilitud como
\begin{eqnarray*}
&&V(\{\alpha_d,\alpha_\theta,\beta_\theta,\alpha_\gamma,\beta_\gamma\},\{\theta_i,\gamma_i\}_{i=1}^{N(t)}|\{d_j,c_j\}_{i=1}^{N(t)})=\\ 
&&\prod_{i=1}^{N(t)} Gamma(d_i|\alpha_d,\theta_i) Gamma(\theta_i|\alpha_d+\alpha_\theta,d_{i-1}+\beta_\theta)\times \\
&&Weibull(c_i|d_i,\gamma_i)(\frac{1}{\gamma})^{d_{i-1}+\alpha_\gamma+1}e^\{-(\frac{\beta_\gamma}{\gamma}+(\frac{c_{i-1}}{\gamma})^{d_i})\} \times \\
&&\times \pi(\alpha_d)\pi(\alpha_\theta)\pi(\beta_\theta)\pi(\alpha_\gamma)\pi(\beta_\gamma)
\end{eqnarray*}
Donde para las variables latentes,
\begin{eqnarray*}
\pi(\theta_i|\alpha_d,\alpha_\theta,\beta_\theta)&\propto& Gamma(d_i|\alpha_d,\theta_i)\times Gamma(\theta_i|\alpha_d+\alpha_\theta,d_{i-1}+\beta_\theta)\\
\\
&=&\frac{\theta_i^{\alpha_d}}{\Gamma(\alpha_d)} d_i^{\alpha_d-1} e^{\{-\theta_id_i\}}\frac{(d_{i-1}+\beta_\theta)^{\alpha_d+\alpha_\theta}}{\Gamma(\alpha_d+\alpha_\theta)}\theta_i^{\alpha_d+\alpha_\theta}e^{\{d_{i-1}+\beta_\theta\}}\\
\\
&=&\frac{d_i^{\alpha_d-1}(d_{i-1}+\beta_\theta)^{\alpha_d+\alpha_\theta}}{\Gamma(\alpha_d)\Gamma(\alpha_d+\alpha_\theta)} \theta_i^{2\alpha_d+\alpha_\theta-1}e^{\{-\theta_i(d_{i-1}+d_i+\beta_\theta)\}}\\
\\
&\propto& \theta_i^{2\alpha_d+\alpha_\theta-1}e^{\{-\theta_i(d_{i-1}+d_i+\beta_\theta)\}}\\
\\
&\Rightarrow& \theta_i \sim Gamma(2\alpha_d+\alpha_\theta,d_i+d_{i-1}+\beta_\theta)
\end{eqnarray*}
Y,
\begin{eqnarray*}
\pi(\gamma_i|\alpha_\gamma,\beta_\gamma,d_i,c_{i-1})&\propto& Weibull(c_i|d_i,\gamma_i)\times (\frac{1}{\gamma_i})^{d_i +\alpha_\gamma+1}e^{\{-(\frac{\beta_\gamma}{\gamma_i}+(\frac{c_{i-1}}{\gamma_i})^{d_i}\}}\\
&=&\frac{d_i}{\gamma_i^{d_i}}c_i^{d_i-1}e^{\{-(\frac{c_i}{\gamma_i})\}}(\frac{1}{\gamma_i})^{d_i+\alpha_\gamma+1}e^{\{-(\frac{\beta_\gamma}{\gamma_i}+(\frac{c_{i-1}}{\gamma_i})^{d_i})\}}\\
&=&d_i c_i^{d_i-1}(\frac{1}{\gamma_i})^{2d_i+\alpha_\gamma+1}e^{\{-(\frac{\beta_\gamma}{\gamma_i}+(\frac{c_{i-1}}{\gamma_i})^{d_i}+(\frac{c_i}{\gamma_i})^{d_i})\}}\\
&\propto&(\frac{1}{\gamma_i})^{2d_i+\alpha_\gamma+1}e^{\{-(\frac{\beta_\gamma}{\gamma_i}+(\frac{c_{i-1}+c_i}{\gamma_i})^{d_i}\}}
\end{eqnarray*}
Las distribuciones que corresponden a los par\'ametros son,
\begin{eqnarray*}
\pi(\alpha_d|...)&\propto& \prod_{i=2}^{N(t)} Gamma(\theta_i|\alpha_d+\alpha_\theta,d_{i-1}+\beta_\theta)\times Gamma(\alpha_d|\alpha_0,\beta_0)\\
\\
&=&\prod_{i=2}^{N(t)}\frac{(d_{i-1}+\beta_\theta)^{\alpha_d+\alpha_\theta}}{\Gamma(\alpha_d+\alpha_\theta)} \theta_i^{\alpha_d+\alpha_\theta-1} e^{\{-\theta_i(d_{i-1}+\beta_\theta)\}}\frac{\beta_0^{\alpha_0}}{\Gamma(\alpha_0)} \alpha_d^{\alpha_0-1}e^{\{-\alpha_d\beta_0\}}\\
\\
&\propto&\prod_{i=2}^{N(t)}\frac{(d_{i-1}+\beta_\theta)^{\alpha_d+\alpha_\theta}}{\Gamma(\alpha_d+\alpha_\theta)} \theta_i^{\alpha_d}\alpha_d^{\alpha_0-1}e^{\{-\alpha_d\beta_0\}}
\end{eqnarray*}
\\
\begin{eqnarray*}
\pi(\alpha_\theta|...)&\propto&\prod_{i=2}^{N(t)} Gamma(\theta_i|\alpha_d+\alpha_\theta,d_{i-1}+\beta_\theta)\times Gamma(\alpha_\theta|\alpha_0,\beta_0)\\
\\
&=&\prod_{i=2}^{N(t)}\frac{(d_{i-1}+\beta_\theta)^{\alpha_d+\alpha_\theta}}{\Gamma(\alpha_d+\alpha_\theta)} \theta_i^{\alpha_d+\alpha_\theta-1} e^{\{-\theta_i(d_{i-1}+\beta_\theta)\}}\frac{\beta_0^{\alpha_0}}{\Gamma(\alpha_0)} \alpha_\theta^{\alpha_0-1}e^{\{-\alpha_\theta\beta_0\}}\\
\\
&\propto& \prod_{i=2}^{N(t)}\frac{(d_{i-1}+\beta_\theta)^{\alpha_d+\alpha_\theta}}{\Gamma(\alpha_d+\alpha_\theta)} \theta_i^{\alpha_\theta}\alpha_\theta^{\alpha_0-1}e^{\{-\alpha_\theta\beta_0\}}
\end{eqnarray*}
\\
\begin{eqnarray*}
\pi(\beta_\theta|...)&\propto&\prod_{i=2}^{N(t)} Gamma(\theta_i|\alpha_d+\alpha_\theta,d_{i-1}+\beta_\theta)\times Gamma(\beta_\theta|\alpha_0,\beta_0)\\
\\
&=&\prod_{i=2}^{N(t)}\frac{(d_{i-1}+\beta_\theta)^{\alpha_d+\alpha_\theta}}{\Gamma(\alpha_d+\alpha_\theta)} \theta_i^{\alpha_d+\alpha_\theta-1} e^{\{-\theta_i(d_{i-1}+\beta_\theta)\}}\frac{\beta_0^{\alpha_0}}{\Gamma(\alpha_0)} \beta_\theta^{\alpha_0-1}e^{\{-\beta_\theta\beta_0\}}\\
\\
&\propto&\prod_{i=2}^{N(t)}(d_{i-1}+\beta_\theta)^{\alpha_d+\alpha_\theta}\beta_\theta^{\alpha_0-1} e^{\{-\beta_\theta(\theta_i+\beta_0)\}}
\end{eqnarray*}
\\
\begin{eqnarray*}
\pi(\alpha_\gamma|...)&\propto&\prod_{i=2}^{N(t)} \pi(\gamma_i|\alpha_\gamma,\beta_\gamma,d_i,c_{i-1})\times Gamma(\alpha_\gamma|\alpha_0,\beta_0)\\
&=&\prod_{i=2}^{N(t)}(\frac{1}{\gamma_i})^{d_i+\alpha_\gamma+1}e^{\{-(\frac{\beta_\gamma}{\gamma_i}+(\frac{c_{i-1}}{\gamma_i})^{d_i})\}}\frac{\beta_0^{\alpha_0}}{\Gamma(\alpha_0)} \alpha_\gamma^{\alpha_0-1}e^{\{-\alpha_\gamma\beta_0\}}\\
\\
&\propto&\prod_{i=2}^{N(t)} (\frac{1}{\gamma_i})^{\alpha_\gamma}\alpha_\gamma^{\alpha_0-1}e^{\{-\alpha_\gamma\beta_0\}}
\end{eqnarray*}
\\
\begin{eqnarray*}
\pi(\beta_\gamma|...)&\propto&\prod_{i=2}^{N(t)} \pi(\gamma_i|\alpha_\gamma,\beta_\gamma,d_i,c_{i-1})\times Gamma(\beta_\gamma|\alpha_0,\beta_0)\\
\\
&=&\prod_{i=2}^{N(t)}(\frac{1}{\gamma_i})^{d_i+\alpha_\gamma+1}e^{\{-(\frac{\beta_\gamma}{\gamma_i}+(\frac{c_{i-1}}{\gamma_i})^{d_i})\}}\frac{\beta_0^{\alpha_0}}{\Gamma(\alpha_0)} \beta_\gamma^{\alpha_0-1}e^{\{-\beta_\gamma\beta_0\}}\\
&\propto&\beta_\gamma^{\alpha_0-1}e^{\{-\beta_\gamma(\frac{1}{\gamma_i}+\beta_0)\}}\\
\\
&\Rightarrow& \beta_\gamma \sim Gamma(\alpha_0,\frac{1}{\gamma_i}+\beta_0)
\end{eqnarray*}
Los par\'ametros a estimar son aquellos correspondientes a las variables latentes, cuyo kernel se estima para cada momento $i$ ($i=1,...,N(t)$), y a las variables observables del modelo. Dado el uso de las variables latentes no existir\'a un \'optimo global para las variables, raz\'on por la cual se requiere el uso de m\'etodos num\'ericos no solo para la estimaci\'on de los par\'ametros y variables latentes sino para analizar las distribuciones que no tienen expresi\'on anal\'itica cerrada, como aquellas de los par\'ametros $\alpha_d,\alpha_\theta,\alpha_\gamma$ y la variable latente $\gamma_i$.\\
\\
Es importante mencionar que estas distribuciones que no tienen forma anal\'itica cerrada son funcioones log-c\'oncavas. Las funcionas log-c\'oncavas son, de acuerdo con \cite{bagnoli2005log}, funciones que se grafican con una curva c\'oncava en los n\'umeros reales positivos y cuyo logaritmo es tambi\'en una funci\'on c\'oncava. Estas funciones tienen el siguiente teorema\\
\begin{teo}
Sea $F$ sea una funci\'on doblemente diferenciable que toma valores positivos con soporte en $(a,b)$ y sea $t$ una funci\'on doblemente diferenciable y monot\'onica que va de $(a',b')$ a $(a,b)=(t(a'),t(b'))$. Se define la funci\'on $\hat{F}$ con soporte en $(a',b')$ para toda $x \in (a',b'), \quad \hat{F}(x)=F(t(x))$. Si F es log-c\'oncava y t una funci\'on c\'oncava, entonces $\hat{F}$ es log-c\'oncava.
\end{teo}
Este teorema tiene como corolario,
\begin{cor}
Sea F una funci\'on con soporte en (a,b). Sea $t$ una transformaci\'on lineal de la l\'inea real hacia si misma, y se define una funci\'on $\hat{F}$ con soporte en $(t(a),t(b))$ tal que $\hat{F}(x)=F(t(x))$. Si F es log-c\'oncava entonces $\hat{F}$ es log-c\'oncava. 
\end{cor}
Seg\'un \cite{bagnoli2005log}, la distribuci\'on Weibull cumple con las caracter\'isticas de log-concavidad si su par\'ametro de forma es mayor o igual a uno, para el caso de la distribuci\'on de los costos este par\'ametro corresponde a la duraci\'on, que por definici\'on es mayor a uno. Tambi\'en la distribuci\'on Gamma de $\alpha_d,\alpha_\theta, \alpha_\gamma$ debe tener el par\'ametro de forma mayor a uno, como sucede para la distribuci\'on Weibull, esta condici\'on se cumple por construcci\'on. De este modo aseguramos la log-concavidad para estas distribuciones que no tienen una f\'ormula anal\'itica cerrada y que se muestrearan de manera previa a la estimaci\'on de par\'ametros para el modelo general de probabilidad.\\
\\
\cite{pitt2002constructing} especifica que la estimaci\'on de m\'axima verosimilitud puede resolverse mediante el algoritmo EM, aunque tambi\'en, debido a que las densidades son dos condicionales de la densidad conjunta puede ligarse con el Muestreador Gibbs.\\
\\
El algoritmo EM es un algoritmo para calcular el estimador de m\'axima verosimilitud, que de acuerdo con \cite{held2014applied}, se define como
\begin{defi}
El Estimador de M\'axima Verosimilitud (EMV) $\hat{\theta}_{MV}$ del par\'ametro $\theta$ se obtiene maximizando la funci\'on de verosimilitud.
\begin{align*}
\hat{\theta}_{MV}=max_{\theta \in \Theta} L(\theta)
\end{align*} 
\end{defi}
Seg\'un \cite{dempster1977maximum} el algoritmo EM calcula el EML mediante iteraciones, cada iteraci\'on consiste en un paso d\'onde se calcula la esperanza y en otro  se maximiza la misma, de ah\'i el nombre de EM. Este algoritmo se relaciona con las variables latentes suponiendo dos variables $x$ y $y$ las cuales se relacionan $x \to y(x)$, donde $y$ son los datos observables.\\
\\
De este modo, an\'alogamente a lo expresado en el cap\'itulo anterior por \cite{pitt2002constructing}, se proponen las siguientes funciones de densidad $f(x|\phi)$ y $g(y|\phi)$; en las cuales, de acuerdo a \cite{dempster1977maximum} los datos completos (variables latentes) $f(x|\cdot)$ se relacionan con los datos incompletos (variables observadas) $g(y|\cdot)$ mediante
\begin{align*}
g(y|\phi)=\int_{\chi(y)} f(x|\phi)dx
\end{align*}
El algoritmo EM se dedica a encontrar un valor de $\phi$ que maximice $g(y|\phi)$ dada la $y$ observada usando la familia asociada de $f(x|\phi)$. Una de las caracterizaciones m\'as simples supone $\phi^{(p)}$ es el valor actual de $\phi$ despu\'es de $p$ iteraciones y $t(x)$ como el estad\'istico suficientes de los datos completos, es decir, el estimador de la variable latente; por lo que la siguiente iteraci\'on se puede desglosar en los siguientes dos pasos:
\begin{itemize}
\item Paso E: Estimar los estad\'isticos suficientes de los datos completos.
	\begin{align*}
	t^{(p)}=E[t(x)|y,\phi^{(p)}]
	\end{align*}
\item Paso M: Determinar $\phi^{(p+1)}$ como soluci\'on a la ecuaci\'on
	\begin{align*}
	E[t(x)|\phi]=t^{(p)}
	\end{align*}
\end{itemize}
Es decir, que si suponemos que $t^{(p)}$ es el estad\'istico suficiente calculado de $x$ observada en la distribuci\'on $f(x|\phi)$ entonces la ecuaci\'on definida en el Paso M se define como el EMV. Este concepto se hace general al definir la siguiente funci\'on
\begin{align*}
Q(\phi'|\phi)=E[log f(x|\phi')|y,\phi]
\end{align*}
Esta funci\'on se asume que existe para toda pareja $(\phi',\phi)$. Se define la iteraci\'on EM para $\phi^{(p)} \to \phi^{(p+1)}$,
\begin{itemize}
\item Calcular $Q(\phi,\phi^{(p)})$.
\item Determinar $\phi^{(p+1)}$ tal que maximice $Q(\phi,\phi^{(p)})$.
\end{itemize}
La idea central es tomar una $\phi'$ que maximice $log f(x|\phi)$, dado que esta distribuci\'on y su correspondiente logaritmo no necesariamente se conoce, se puede maximizar los datos observados y $\phi^{(p)}$.\\
\\
El algoritmo EM es muy \'util pues por su estructura iterativa puede dar resultados a modelos de probabilidad muy complejos, adem\'as de que al igual que el Muestreador de Gibbs, utiliza una estructura subyacente o de variables latentes. En la siguiente secci\'on se explorar\'a con detalle el Muestreador de Gibbs y sus implicaciones con el modelo general de probabilidad relativo a este trabajo.
\section{Slice Sampler}
En la funci\'on de verosimilitus definida en la secci\'on anterior, las distribuciones de la variable latente $\gamma_i$ y de los par\'ametros $\alpha_d,\alpha_\theta,\alpha_\gamma$ no se pueden expresar de una forma anal\'itica cerrada. Es por esto que antes de empezar a estimar la funci\'on de verosimilitud es necesario muestrear primero estas distribuciones para lograr que los m\'etodos de estimaci\'on funcionen de la mejor manera. Este primer acercamiento se hace mediante el Slice Sampler.\\
\\
De acuerdo con \cite{neal2003slice} existen varias aplicaciones para esta manera de muestrear, desde la manera m\'as simple con una distribuci\'on univariada como alternativa al Muestreador de Gibbs hasta la m\'as compleja donde se pueden adaptar relaciones de dependencia entre las variables, permitiendo mayor flexibilidad al Muestreador de Gibbs. Esta es la clase de Slice Sampler que se utilizar\'a en este trabajo de investigaci\'on.\\
\\
La idea detr\'as del concepto del Slice Sampler es que si queremos muestrear la distribuci\'on de una variable $x$ que toma valores en el conjunto $\mathbb{R}^n$, cuya densidad sea proporcional a alguna funci\'on $f(x)$, entonces se muestrea de forma uniforme en la regi\'on por debajo de la curva de $f(x)$ con dimensi\'on $(n+1)$. Esta idea se puede concretar introduciendo una variable real auxiliar $y$ y definiendo la distribuci\'on conjunta de $x$ y $y$ que es uniforme sobre la regi\'on debajo de la curva de $f(x)$, tal que, $U=\{(x,y):0<y<f(x)\}$. Es decir, que para muestrear $x$, muestreamos conjuntamente $(x,y)$ para despu\'es ignorar $y$.\\
\\
Sin embargo, dado que generar puntos independientes muestreados de la distribuci\'on $U$ no siempre es sencillo, se puede definir una Cadena de Markov que converja a esta distribuci\'on uniforme. Esto se hace mediante el muestreo alternado de la distribuci\'on condicional de $y|x$ la cual es uniforme en el intervalo $(0,f(x))$ y de la distribuci\'on condicional de $x|y$ la cual tambi\'en es uniforme sobre la regi\'on $S=\{x_y<f(x)\}$, la cual es nombrada como la $rebanada$ definida por $y$. El procedimiento para construir la Cadena de Markov para una distribuci\'on univariada $f(x)$, tomando el valor inicial $x_0$, de acuerdo con \cite{neal2003slice}, es:
\begin{itemize}
\item Se extrae un valor real $y$ uniforme en $(0,f(x))$, definiendo una $rebanada$ horizontal $S=\{x:y<f(x)\}$. Es importante notar que $x_0$ est\'a siempre dentro de $S$.
\item Se encuentra un intervalo $I=(L,R)$ en la vecindad de $x_0$ que contenga toda, o la mayor parte, de la $rebanada$.
\item Se extrae un nuevo punto, $x_1$, de la parte de la $rebanada$ que est\'a dentro del intervalo $I$.
\end{itemize}
En el primer paso del procedimiento se elige la variable auxiliar que es caracter\'istica al Slice Sampler, pues este valor no es necesario de una iteraci\'on de la Cadena de Markov a la siguiente; mientras que los siguientes dos pasos pueden ser implementados de muchas maneras en tanto que la Cadena de Markov resultante permita que la distribuci\'on definida $f(x)$ permanezca invariante. El siguiente problema que se enfrenta es delimitar el intervalo, pues necesita ser lo suficientemente grande para que el nuevo punto ($x_1$) est\'e lo m\'as lejos del anterior ($x_0$) dentro de la misma $rebanada$, pero el intervalo tampoco puede salirse de la misma pues eso volver\'ia ineficiente al muestreo.\\
\\
Para garantizar convergencia en la distribuci\'on $f(x)$ y su invarianza, la Cadena de Markov debe ser erg\'odica. Seg\'un \cite{neal2003slice}, para demostrar que la funci\'on de distribuci\'on permanece invariante, suponemos que el estado inicial $x_0$ se distribuye $f(x)$, en el primer paso del procedimiento la distribuci\'on conjunta es con las variables $x_0$ y $y$, por lo que al actualizar $x_0$ a $x_1$ la funci\'on de distribuci\'on conjunta se mantiene invariante, ignorando as\'i la variable $y$. La distribuci\'on de $x_1$ es la distribuci\'on marginal de la conjunta, es decir, la funci\'on $f(x)$ definida. De este modo, lo \'unico que se necesita demostrar que la selecci\'on de $x_0$ y $x_1$ en los siguientes dos pasos del procedimiento deja a la distribuci\'on conjunta de $x$ y $y$ invariante, y con la distribuci\'on condicional sobre $S=\{x:y<f(x)\}$, es decir, la $rebanada$ definida por $y$. Esta invarianza se puede demostrar si la probabilidad de que $x_1$ sea el pr\'oximo estado dado que el estado actual es $x_0$ es igual a la probabilidad de que $x_0$ sea el pr\'oximo estado dado que el estado actual es $x_1$, para cualquier $x_0$ y $x_1$ en $S$.\\
\\
Este es el procedimiento que aplica para cuando la distribuci\'on es univariada, sin embargo, si esta llegara a ser una distribuci\'on multivariada ($x=(x_1,...,x_n)$) existen dos caminos para hacer el Slice Sampler: el primero es muestrear para cada variable por separado; para esto es necesario poder calcular la funci\'on $f_i(x_i)$ y que esta sea proporcional a $p(x_i|\{x_j\}_{j \neq i})$, donde $\{x_j\}_{j \neq i}$ son los valores de las variables. El otro camino es seguir el mismo procedimiento que se defini\'o para las distribuciones univariadas, solamente que en el segundo paso se reemplaza el intervalo con un hiperrect\'angulo $H=\{x:L_i<x_i<R_i, \quad i=1,...,n\}$ donde $L_i$ y $R_i$ definen la extensi\'on del hiperrect\'angulo a lo largo del eje para la variable $x_i$.\\
\\
En el caso de las distribuciones de los par\'ametros $\alpha_d,\alpha_\theta,\alpha_\gamma$ y de la variable latente $\gamma_i$ son distribuciones con una sola variable, por lo que el Slice Sampler a utilizar para estimar es el de una sola variable. Ahora, una vez estimado estas distribuciones es necesario utilizar el Muestreador de Gibbs que se desarrolla en la siguiente secci\'on para la estimaci\'on del modelo general de probabilidad.
\section{El Muestreador de Gibbs}
Como mencionado en la secci\'on anterior, la estimaci\'on de par\'ametros del modelo general de probabilidad que se utilizar\'a en este trabajo no se puede hacer a trav\'es de m\'etodos anal\'iticos tradicionales, por lo que se utilizar\'an m\'etodos num\'ericos. Entre estos se encuentran el algoritmo EM y el Muestreador de Gibbs, el algoritmo EM fue descrito en la secci\'on anterior y aunque \'util para el an\'alisis del modelo presentado, el Muestreador de Gibbs tiene una interpretaci\'on m\'as simple.\\
\\
De acuerdo con \cite{gelman2014bayesian}, la simulaci\'on a trav\'es de las cadenas de Markov tambi\'en llamadas Cadenas de Markov v\'ia simulaci\'on Monte Carlo (MCMC, por sus siglas en ingl\'es) es un m\'etodo basado en las realizaciones de los valores de $\theta$ de distribuciones aproximadas y despu\'es corrigiendo esas realizaciones para poder mejorar la distribuci\'on posterior de $p(\theta|y)$. Estas realizaciones se realizan de manera iterativa. Una de estas simulaciones MCMC es el Muestreador de Gibbs.\\
\\
Normalmente el Muestreador Gibbs se asocia con la estad\'istica bayesiana aunque puede ser \'util tambi\'en en la visi\'on cl\'asica de la estad\'istica, seg\'un \cite{casella1992explaining} este algoritmo es una t\'ecnica que genera variables aleatorias indirectamente de distribuciones marginales sin tener que calcular la densidad, debido a que se basa en las propiedades principales de las Cadenas de Markov como la estacionareidad para simplificar c\'alculos y tener estimados m\'as precisos.\\
\\
Siguiendo la ilustraci\'on de \cite{casella1992explaining}, supongamos que tenemos una distribuci\'on conjunta $f(\theta,y_1,y_2,...,y_p)$\\
\[f(\theta)=\int \cdots \int f(\theta,y_1,y_2,...,y_p) dy_1,dy_2,...,dy_p\]
Si el inter\'es se encuentra en la marginal $f(\theta)$ y \'esta es demasiado complicada para calcularse directamente, con el Muestreador de Gibb se puede generar una muestra $\theta_1,...,\theta_m \sim f(\theta)$ sin la necesidad de calcular la distribuci\'on marginal. Esto permite obtener informaci\'on de la misma con alto grado de precisi\'on.\\
\\
Para ejemplificar mejor el mecanismo del Muestreador de Gibbs se toman dos variables aleatorias $(\Theta,Y)$. El algoritmo genera una muestra de $f(\theta)$ muestreando de las distribuciones condicionales $f(\theta|y)$ y $f(y|\theta)$ que son la que normalmente se conocen en los modelos estad\'isticos. Esta muestra se obtiene mediante, lo que \cite{casella1992explaining} nombra como, una secuencia de Gibbs $(Y'_0,\theta'_0,Y'_1,\theta'_1,...,Y'_k,\theta'_k)$ que de manera iterativa genera variables aleatorias a partir de valores iniciales especificados $(Y'_0=y'_0)$.\\
\\El proceso iterativo es como sigue\\
\begin{align*}
\theta'_j \sim f(\theta|Y'_j=y'_j)\\
Y'_{j+1} \sim f(y|\theta'_j=x'_j)
\end{align*}
Si la muestra es suficientemente grande, es decir, que si $k \rightarrow \infty$ la distribuci\'on de $\theta'_k$ converger\'a con la verdadera distribuci\'on marginal de $\theta$.\\
\\
El Muestreador de Gibbs puede pensarse como una implementaci\'on pr\'actica del concepto de que solo conociendo las distribuciones marginales se puede determinar la distribici\'on conjunta. Esto ser\'ia cierto en la mayor\'ia de los casos bivariados, el procedamiento no es tan directo para los casos multivariados.\\
\\
De acuerdo con \cite{casella1992explaining} para el caso bivariado, suponemos dos variables aleatorias $\theta,Y$, de las cuales se conocen sus distribuciones condicionales $f_{\Theta|Y}(\theta|y)$ y $f_{Y|\Theta}(y|\theta)$. A partir de estas podr\'iamos calcular la funci\'on marginal de $\theta$ y la distribuci\'on conjunta de ambas variables, mediante  el siguiente argumento:\\
\[f_\theta(\theta)=\int f_{\theta Y}(\theta,y)dy\]
donde la distribuci\'on conjunta es a\'un desconocida, tomando el hecho que $f_{\theta Y}(\theta,y)=f_{\theta|Y}(\theta|y)f_Y(y)$ tendr\'iamos que,\\
\[f_\theta(\theta)=\int f_{\theta|Y}(\theta|y)f_Y(y) dy\]
Asimismo, si sustituimos la distribuci\'on marginal de $y$ ($f_Y(y)$) con el mismo argumento utilizado para la distribuci\'on marginal de $\theta$, se tiene que
\begin{eqnarray*}
f_\theta(\theta) &=& \int f_{\theta|Y}(\theta|y) f_{Y|\theta}(y|t) f_\theta(t)dt dy\\
       &=& \int [ \int  f_{\theta|Y}(\theta|y)f_{Y|\theta}(y|t) dy]  f_\theta(t) dt
\end{eqnarray*}
Esta ecuaci\'on es una forma limitada de la iteraci\'on de Gibbs, ilustrando como las distribuciones condicionales producen una distribuci\'on marginal. Aunque la distribuci\'on conjunta de las variables determinan las distribuciones condicionales y marginales, no siempre las condicionales determinen de manera tan directa la distribuci\'on marginal. Esto es cierto no solo para los casos bivariados, sino que se extiende a los multivariados.\\
\\
En cuantas m\'as variables existan, el problema se vuelve m\'as complejo pues la relaci\'on entre las condicionales, marginales y conjuntas se vuelve m\'as intrincada. Por ejemplo, la relaci\'on $condicional \times marginal = conjunta$ no se sontiene para todas las condicionales y marginales. Pero se pueden hacer varios conjuntos de variables y construir las ecuaciones integrales para calcular la distribuci\'on marginal de inter\'es.\\
\\
Para casos multivariados \cite{casella1992explaining} supone las variables aleatorias $X,Y,Z$ con inter\'es en la distribuci\'on $f_X(x)$. Para esto, se toman las variables $(Y,Z)$ como una sola variable, lo que resultar\'ia en\\
\[f_X(x)= \int [ \int \int f_{X|YX}(x|y,z)f_{YZ|X}(y,z|t)dy dz] f_X(t) dt\]
De esta manera, muestreando iterativamente de $f_{X|YZ}$ y $f_{YZ|X}$ resultar\'ian en una serie de variables aleatorias que convergen en $f_X(x)$. Por otro lado, el Muestreador de Gibb muestrear\'ia iterativamente las distribuciones $f_{X|YZ}, f_{Y|XZ}, f_{Z|X}$, de tal modo que en la j-\'esima iteraci\'on se tendr\'ia,\\
\begin{align*}
X'_j \sim f(x|Y'_j = y'_j, Z'_j=z'_j)\\
Y'_{j+1} \sim f(y|X'_j=x'_j, Z'_j=z'_j)\\
Z'_{j+1} \sim f(z|X'_j=x'_j, Y'_{j+1}=y'_{j+1})
\end{align*}
Este esquema de iteraciones nos produce una secuencia de Gibbs,\\
\[Y'_0,Z'_0,X'_0,Y'_1,Z'_1,X'_1,...\]
con la misma propiedad de convergencia que en el caso bivariado, ente m\'as grande es la $k$, $X'_k=x'_k$ es un punto de la distribuci\'on marginal $f(x)$.\\
\\
De este modo queda evidenciada la utilidad del Muestreador de Gibbs en el ahorro de c\'alculos y la precisi\'on de sus resultados. Como mencionado en la secci\'on anterior, esta t\'ecnica inferencial es muy \'util tanto en la estad\'istica bayesiana como en la cl\'asica, en la primera para calcular la distribuci\'on posterior y en la \'ultima, para calcular la funci\'on de verosimilitud. Seg\'un \cite{gelman2014bayesian}, la clave del \'exito de este m\'etodo es la iteraci\'on en la cual las distribuciones aproximadas mejoran hasta converger en la distribuci\'on deseada.\\
\\
Tomando la verosimilitud extendida definida anteriormente, primero se fijan los valores iniciales para los par\'ametros $\alpha_d^{(0)},\alpha_\theta^{(0)},\beta_\theta^{(0)},\alpha_\gamma^{(0)},\beta_\gamma^{(0)}$ y para las variables latentes $\{\theta_i^{(0)}\}_{i=1}^{N(t)},\{\gamma_i^{(0)}\}_{i=1}^{N(t)}$ y para cada $k=1,...,N(t)$ tenemos la siguiente distribuci\'on que ses proporcional a la verosimilitud,
\begin{align*}
\pi(\alpha_d^{(k)},\alpha_\theta^{(k)},\beta_\theta^{(k)},\alpha_\gamma^{(k)},\beta_\gamma^{(k)}|\{\theta_i^{(k-1)}\}_{i=1}^{N(t)},\{\gamma_i^{(k-1)}\}_{i=1}^{N(t)},\{d_i,c_i\}_{i=1}^{N(t)})
\end{align*}
Este es el principio necesario para utilizar el Muestreador de Gibbs de modo que se estimen los par\'ametros en base a las variables latentes que a su vez se estiman en base a las observaciones para que con los par\'ametros estimados se estimen las variables latentes que ayuden a predecir futuras observaciones. Una vez que se tiene el concepto general de la aplicaci\'on de esta t\'ecnica de muestreo para el objetivo de este trabajo, es necesario considerar las maneras de implementarlo.\\
\\
Para la implementaci\'on del Muestreador de Gibbs en este trabajo se utilizar\'a el programa JAGS (Solo Otro Muestreador de Gibbs, por sus siglas en ingl\'es). Este programa es una extensi\'on del programa BUGS (Inferencia Bayesiana Usando el Muestreador de Gibbs, por sus siglas en ingl\'es), que normalmente es utilizado para la exploraci\'on de modelos Markov multivariados en el contexto de estad\'istica actuarial. JAGS es un programa que autom\'aticamente construye las cadenas de Matkov v\'ia simulaci\'on Monte Carlo (MCMC) para modelos multivariados.\\
\\
Para lograr expresar estos problemas con BUGS, explicado por sus creadores \cite{plummer2003jags}, se necesitan tomar en cuenta dos distribuciones:
\begin{itemize}
\item Una distribuci\'on que describa la probabilidad de estar en el estado $j$ en el tiempo $t$ dado que el sujeto estaba en el estado $i$ al tiempo $0$.
\item Una distribuci\'on de supervivencia que describa el tiempo en un estado absorbente, que bien, es conocida o censorada a la derecha.
\end{itemize}
La necesidad de estas distribuciones aunado a la necesidad de una herramienta que ayude a explorar modelos gr\'aficos es lo que da origen a JAGS. Es decir, el programa toma la descripci\'on del modelo general de probabilidad multivariado y regresa un muestreo de MCMC de la distribuci\'on posterior.\\
\\
De este modo, se establece no solo las bases para la inferencia y predicci\'on de futuras observaciones en base a la verosimilud extendida y la resoluci\'on de su funci\'on sino tambi\'en la implementaci\'on num\'erica de la misma. Una vez que se definieron estas herramientas, lo que resta es la adaptaci\'on del modelo a la ilustraci\'on con los datos, esto se explorar\'a en el siguiente cap\'itulo.  