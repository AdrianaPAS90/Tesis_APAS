\chapter{Estad\'istica Bayesiana}
\section{Paradigma Bayesiano}
El paradigma bayesiano se refiere a una manera de hacer inferencia basado en el trabajo del ingl\'es Thomas Bayes. En este paradigma se establece que la hip\'otesis se va actualizando de acuerdo a la nueva informaci\'on  relevante. Seg\'un \cite{gelman2014bayesian}, una de las principales razones para el pensamiento bayesiano es que facilita la interpretaci\'on basada en el sentido com\'un de conclusiones estad\'isticas. \\
%\cite{kruschke2014doing} al principio la distribuci\'on de probabilidades entre las opciones posibles se realiza al conocimiento previo que se tenga de la situaci\'on; por lo que la inferencia bayesiana consiste en la relocaci\'on o actualizaci\'on de las probabilidades entre las opciones conforme se vayan realizando nuevas observaciones.\\
\\
De acuerdo con \cite{gelman2014bayesian} la inferencia bayesiana se hace en base en una evaluaci\'on retrospectiva del procedimiento utilizado para estimar el par\'ametro sobre la distribuci\'on de todas las posibles observaciones. Es decir, que mediante la regla de Bayes se describe la relaci\'on entre la asiganci\'on previa de la probabilidad y la reasignaci\'on de esta misma condicionada a los datos observados. El paradigma est\'a basado en la regla o teorema de Bayes.\\
\\
Una definici\'on de la probabilidad condicional de $y$ dado $x$  ser\'a la divisi\'on de la funci\'on conjunta de probabilidad entre la funci\'on de probabilidad de $x$. Es decir,
\begin{align*}
p(y|x)=\frac{p(x,y)}{p(x)}
\end{align*}
O en otras palabras, la probabilidad de $y$ $suceda$ dado $x$ es la probabilidad de que $sucedan$ ambos eventos relativo a que $x$ $suceda$ en absoluto.\\
\\
Tomando en cuenta esta definici\'on de la probabilidad condicional, el teorema de Bayes, se define como
\begin{align*}
p(y|x)=\frac{p(x|y)p(y)}{p(x)}
\end{align*}
El Teorema de Bayes resulta muy \'util cuando el modelo de probabilidad se basa en variables observables y  par\'ametros, $D$ y $\theta$ respectivamente. De este modo, el modelo se escribe como
\begin{align*}
p(\theta|D)=\frac{p(D|\theta)p(\theta)}{p(D)}
\end{align*}
Donde los elementos de esta ecuaci\'on significan
\begin{itemize}
\item $p(\theta|D)=$ la distribuci\'on posterior, es decir, la probabilidad de $\theta$ tomando en cuenta las observaciones.
\item $p(D|\theta)=$ la verosimilitud, es decir, la probabilidad de los datos generados por el modelo con el par\'ametro $\theta$.
\item $p(\theta)=$ la distribuci\'on previa, es decir, la probabilidad de $\theta$ sin tomar en cuenta las observaciones $D$.
\item $p(D)=$ la distribuci\'on de las observaciones, es decir, la probabilidad total de las observaciones, ponderadas por todos los valores que puede tomar el par\'ametro de acuerdo al peso que se le asigna.
\end{itemize}
Esta misma ecuaci\'on se puede reescribir como,
\begin{eqnarray*}
p(\theta|D)&=&\frac{p(D|\theta)p(\theta)}{p(D)}\\
		   &\propto & p(D|\theta)p(\theta)\\
		   &\propto & verosimilitud \times inicial
\end{eqnarray*}
La distribuci\'on posterior est\'a en funci\'on del par\'ametro, por lo que la distribuci\'on posterior es proporcional a la multiplicaci\'on de la funci\'on de verosimilitud por la distribuci\'on inicial del par\'ametro. En otras palabras, la distribuci\'on previa del par\'ametro es la informaci\'on a priori del mismo, que se va actualizando con las observaciones, tomando la informaci\'on relevante al par\'ametro. Este mismo principio puede extenderse para varios par\'ametros.\\
\\
Como describe \cite{gelman2014bayesian}, esta l\'ogica es similar para hacer inferencias sobre futuras observaciones. Una vez que se tienen todas las observaciones $D=(d_1,...,d_n)$ se quiere inferir la siguiente observaci\'on $d_{n+1}$. La distribuci\'on de esta observaci\'on se llama la distribuci\'on llamada distribuci\'on posterior predictiva, posterior porque toma la informaci\'on de las observaciones pasadas y predictiva porque predice la siguiente observaci\'on,
\begin{eqnarray*}
p(d_{n+1}|D)&=&\int p(d_{n+1},\theta|D) d\theta \\
			&=& \int p(d_{n+1}|\theta,D)p(\theta|D)d\theta \\
			&=& \int p(d_{n+1}|\theta)p(\theta|D)d\theta
\end{eqnarray*}
En la segunda y tercera l\'inea de la ecuaci\'on se muestra la distribuci\'on posterior predictiva como un promedio de las distribuciones predictivas condicionales de la distribuci\'on posterior del par\'ametro $\theta$. En la \'ultima l\'inea se asume la independencia condicional de $D$ y $d_{n+1}$ dado $\theta$.\\
\\
Como enunciado en \cite{smith2010bayesian}, en el modelo bayesiano de inferencia, como descrito anteriormente; la evidencia, las observaciones y los argumentos cient\'ificos se utilizan para soportar la distribuci\'on de probabilidad del modelo propuesto. Por otro lado, en el an\'alisis bayesiano de decisi\'on el Tomador de Decisiones debe tomar este sustento evidencial y cient\'ifico para resolver el problema espec\'ifico que se encuentre.\\
\\
Es decir, en un ambiente de incertidumbre tenemos el espacio de decisi\'on $A$ donde cualquier decisi\'on puede ser tomada por el Tomador de Decisi\'on y $\Phi$ es el espacio de posibles resultados $\phi$. El Tomador de Decisiones debe cuantificar las consecuencias de elegir cada decisi\'on $a \in A$ para todos los posibles resultados $\phi \in \Phi$. Con esta informaci\'on se deben especificar la funci\'on de p\'erdida $L(a,\phi)$, en la cual se mide la p\'erdida de tomar la decisi\'on $a$ con el resultado $\phi$. Otra funci\'on a especificar es la funci\'on de probabilidad $p(\phi)$ que da las probabilidades de los posibles resultados $\phi$ antes de tomar la decisi\'on $a$; esta funci\'on representa la incertidumbre que enfrenta el Tomador de Decisi\'on. De este modo, la mejor decisi\'on que se puede tomar es aquella que minimice la p\'erdida esperada,
\begin{align*}
\bar{L}(a)= \int_{\phi \in \Phi} L(a,\phi)p(\phi)
\end{align*}
Con el enfoque del an\'alisis bayesiano de decisi\'on los problemas cl\'asicos de inferencia como la estimaci\'on puntual, estimaci\'on por regiones y contraste de hip\'otesis pueden resolverse de esta manera. Adem\'as, los estimadores obtenidos no solo suelen coincidir con los estimadores cl\'asicos en algunos casos, sino en otros casos de hecho los mejoran.\\
\\
En el desarrollo de este trabajo de investigaci\'on, veremos que la estimaci\'on del modelo general de probabilidad no se puede realizar a trav\'es de m\'etodos anal\'iticos cerrados, por lo que se sugiere la utilizaci\'on de m\'etodos num\'ericos. El m\'etodo n\'umerico a utilizar, por la naturaleza del estudio, ser\'a el Muestreador de Gibbs, que se describe en la siguiente secci\'on.

\section{El Muestreador de Gibbs}
Como mencionado en la secci\'on anterior, la estimaci\'on de par\'ametros del modelo general de probabilidad que se utilizar\'a en este trabajo no se puede hacer a trav\'es de m\'etodos anal\'iticos tradicionales, por lo que se utilizar\'an m\'etodos num\'ericos. Existen varios m\'etodos, entre estos se encuentran el algoritmo EM y el Muestreador de Gibbs, el algoritmo EM ser\'a m\'as desarrolado en la siguiente secci\'on y aunque \'util para el an\'alisis del modelo presentado, el Muestreador de Gibbs tiene una interpretaci\'on m\'as simple.\\
\\
De acuerdo con \cite{gelman2014bayesian}, la simulaci\'on a trav\'es de las cadenas de Markov tambi\'en llamadas Cadenas de Markov v\'ia simulaci\'on Monte Carlo (MCMC, por sus siglas en ingl\'es) consiste en construir una Cadena de Markov cuya distribuci\'on estacionaria (l\'imite) sea una distribuci\'on de la cual se pretenda simular. Una de estas simulaciones MCMC es el Muestreador de Gibbs.\\
\\
Aunque el Muestreador de Gibbs pueda ser \'util en la visi\'on cl\'asica de la estad\'istica, normalmente el Muestreador Gibbs se asocia con la estad\'istica bayesiana, como es el caso de este trabajo. Seg\'un \cite{casella1992explaining} este algoritmo es una t\'ecnica que genera variables aleatorias indirectamente de distribuciones marginales sin tener que calcular la densidad, debido a que se basa en las propiedades principales de las Cadenas de Markov como la estacionareidad para simplificar c\'alculos y tener estimados m\'as precisos.\\
\\
Siguiendo la ilustraci\'on de \cite{casella1992explaining}, supongamos que tenemos una distribuci\'on conjunta $f(\theta,y_1,y_2,...,y_p)$\\
\[f(\theta)=\int \cdots \int f(\theta,y_1,y_2,...,y_p) dy_1,dy_2,...,dy_p\]
Si el inter\'es se encuentra en la marginal $f(\theta)$ y \'esta es demasiado complicada para calcularse directamente, con el Muestreador de Gibb se puede generar una muestra $\theta_1,...,\theta_m \sim f(\theta)$ sin la necesidad de calcular la distribuci\'on marginal. Esto permite obtener informaci\'on de la misma con alto grado de precisi\'on.\\
\\
Para ejemplificar mejor el mecanismo del Muestreador de Gibbs se toman dos variables aleatorias $(\Theta,Y)$. El algoritmo genera una muestra de $f(\theta)$ muestreando de las distribuciones condicionales $f(\theta|y)$ y $f(y|\theta)$ que son la que normalmente se conocen en los modelos estad\'isticos. Esta muestra se obtiene mediante, lo que \cite{casella1992explaining} nombra como, una secuencia de Gibbs $(Y'_0,\theta'_0,Y'_1,\theta'_1,...,Y'_k,\theta'_k)$ que de manera iterativa genera variables aleatorias a partir de valores iniciales especificados $(Y'_0=y'_0)$.\\
\\El proceso iterativo es como sigue\\
\begin{align*}
\theta'_j \sim f(\theta|Y'_j=y'_j)\\
Y'_{j+1} \sim f(y|\theta'_j=\theta'_j)
\end{align*}
Si la muestra es suficientemente grande, es decir, que si $k \rightarrow \infty$ la distribuci\'on de $\theta'_k$ converger\'a con la verdadera distribuci\'on marginal de $\theta$.\\
\\
El Muestreador de Gibbs puede pensarse como una implementaci\'on pr\'actica del concepto de que solo conociendo las distribuciones marginales se puede determinar la distribici\'on conjunta. Esto ser\'ia cierto en la mayor\'ia de los casos bivariados, el procedamiento no es tan directo para los casos multivariados.\\
\\
De acuerdo con \cite{casella1992explaining} para el caso bivariado, suponemos dos variables aleatorias $\theta,Y$, de las cuales se conocen sus distribuciones condicionales $f_{\Theta|Y}(\theta|y)$ y $f_{Y|\Theta}(y|\theta)$. A partir de estas podr\'iamos calcular la funci\'on marginal de $\theta$ y la distribuci\'on conjunta de ambas variables, mediante  el siguiente argumento:\\
\[f_\theta(\theta)=\int f_{\theta Y}(\theta,y)dy\]
donde la distribuci\'on conjunta es a\'un desconocida, tomando el hecho que $f_{\theta Y}(\theta,y)=f_{\theta|Y}(\theta|y)f_Y(y)$ tendr\'iamos que,\\
\[f_\theta(\theta)=\int f_{\theta|Y}(\theta|y)f_Y(y) dy\]
Asimismo, si sustituimos la distribuci\'on marginal de $y$ ($f_Y(y)$) con el mismo argumento utilizado para la distribuci\'on marginal de $\theta$, se tiene que
\begin{eqnarray*}
f_\theta(\theta) &=& \int f_{\theta|Y}(\theta|y) f_{Y|\theta}(y|t) f_\theta(t)dt dy\\
       &=& \int [ \int  f_{\theta|Y}(\theta|y)f_{Y|\theta}(y|t) dy]  f_\theta(t) dt
\end{eqnarray*}
Esta ecuaci\'on es una forma limitada de la iteraci\'on de Gibbs, ilustrando como las distribuciones condicionales producen una distribuci\'on marginal. Aunque la distribuci\'on conjunta de las variables determinan las distribuciones condicionales y marginales, no siempre las condicionales determinen de manera tan directa la distribuci\'on marginal. Esto es cierto no solo para los casos bivariados, sino que se extiende a los multivariados.\\
\\
En cuantas m\'as variables existan, el problema se vuelve m\'as complejo pues la relaci\'on entre las condicionales, marginales y conjuntas se vuelve m\'as intrincada. Por ejemplo, la relaci\'on $condicional \times marginal = conjunta$ no se sontiene para todas las condicionales y marginales. Pero se pueden hacer varios conjuntos de variables y construir las ecuaciones integrales para calcular la distribuci\'on marginal de inter\'es.\\
\\
Para casos multivariados \cite{casella1992explaining} supone las variables aleatorias $X,Y,Z$ con inter\'es en la distribuci\'on $f_X(x)$. Para esto, se toman las variables $(Y,Z)$ como una sola variable, lo que resultar\'ia en\\
\[f_X(x)= \int [ \int \int f_{X|YX}(x|y,z)f_{YZ|X}(y,z|t)dy dz] f_X(t) dt\]
De esta manera, muestreando iterativamente de $f_{X|YZ}$ y $f_{YZ|X}$ resultar\'ian en una serie de variables aleatorias que convergen en $f_X(x)$. Por otro lado, el Muestreador de Gibb muestrear\'ia iterativamente las distribuciones $f_{X|YZ}, f_{Y|XZ}, f_{Z|X}$, de tal modo que en la j-\'esima iteraci\'on se tendr\'ia,\\
\begin{align*}
X'_j \sim f(x|Y'_j = y'_j, Z'_j=z'_j)\\
Y'_{j+1} \sim f(y|X'_j=x'_j, Z'_j=z'_j)\\
Z'_{j+1} \sim f(z|X'_j=x'_j, Y'_{j+1}=y'_{j+1})
\end{align*}
Este esquema de iteraciones nos produce una secuencia de Gibbs,\\
\[Y'_0,Z'_0,X'_0,Y'_1,Z'_1,X'_1,...\]
con la misma propiedad de convergencia que en el caso bivariado, ente m\'as grande es la $k$, $X'_k=x'_k$ es un punto de la distribuci\'on marginal $f(x)$.\\
\\
De este modo queda evidenciada la utilidad del Muestreador de Gibbs en el ahorro de c\'alculos y la precisi\'on de sus resultados. Como mencionado en la secci\'on anterior, esta t\'ecnica inferencial es muy \'util tanto en la estad\'istica bayesiana como en la cl\'asica, en la primera para calcular la distribuci\'on posterior y en la \'ultima, para calcular la funci\'on de verosimilitud. Seg\'un \cite{gelman2014bayesian}, la clave del \'exito de este m\'etodo es la iteraci\'on en la cual las distribuciones aproximadas mejoran hasta converger en la distribuci\'on deseada.\\
\\
El Muestreador de Gibbs tradicional puede ser un poco limitado en lo que se refiere a su aplicaci\'on en un problema que se desarrolla a trav\'es del tiempo; sin embargo, este se puede adaptar a los requerimientos particulares del caso. \cite{carter1996markov} exponen un caso particular en el contexto de Modelos Espacio-Estado Gaussianos, que aunque no es exactamente el modelo planteado en este trabajo, algunas de las ideas expuestas pueden ser extendidas.\\
\\
El modelo planteado por \cite{carter1996markov} es,
\begin{align*}
y_i=h_i'x_i+\gamma_ie_i; \qquad x_i=F_ix_{i-1}+\Gamma_iu_i
\end{align*}
Donde las observaciones $y_i$ son escalares y $x_i$ es el vector de estados de dimensi\'on $m\times 1$. Los errores $e_i$ y $u_i$ son independientes y se distribuyen $N(0,\sigma^2)$ y $N(0,\tau^2I_m)$. Los coeficientes $h_i,\gamma_i,F_i,\Gamma_i$ son determinados por la variable discreta $K_i$. Usando la notaci\'on para el vector de observaciones de $Y:=(y_1,...,y_n)'$, el vector total de estados $X:=(x_1',...,x_n')'$, $K:=(K_1,...,K_n)$. Sea $g_i:=h_i'x_i$, por lo que $G:=(g_1,...,g_n)'$. Asumiendo que $\sigma^2, \tau^2$ y $K$ son independientes; las distribuciones priori es Gamma Inversa y la distribuci\'on priori de $K$ es una Cadena de Markov con probabilidades de transici\'on conocidas. Tambi\'en se asume que dado $K_1$ y $\tau^2$, la distribuci\'on de $x_1$ es normal.\\
\\
Se propone el siguiente muestreador para estimar $X,K,\sigma^2$ y $\tau^2$, mediante la generaci\'on de las siguientes distribuciones condicionales,
\begin{enumerate}
\item $p(\tau^2|Y,G,K,\sigma^2)$ que se puede reescribir como $p(\tau^2|G,K)$.
\item $p(K_i|Y,K_{j \neq i},\sigma^2,\tau^2)$ para $i=1,...,n$.
\item $p(X|Y,K,\sigma^2,\tau^2)$.
\item $p(\sigma^2|Y,X,K,\tau^2)$ que se puede reescribir como $p(\sigma^2|Y,G,K)$.
\end{enumerate}
Este muestreador que se propone, a diferencia del Muestreador de Gibbs, la variable $K_i$ es generada sin estar condicionada a la variable de estados $X$. Es decir, que se pueden hacer modificaciones a los muestreadores de tal manera que se adapten al modelo a trav\'es del tiempo manteniendo la estructura MCMC.\\
\\
Para la implementaci\'on del Muestreador de Gibbs en este trabajo se utilizar\'a el programa JAGS (Solo Otro Muestreador de Gibbs, por sus siglas en ingl\'es). Este programa es una extensi\'on del programa BUGS (Inferencia Bayesiana Usando el Muestreador de Gibbs, por sus siglas en ingl\'es), que normalmente es utilizado para la exploraci\'on de modelos Markov multivariados en el contexto de estad\'istica actuarial. JAGS es un programa que autom\'aticamente construye las cadenas de Matkov v\'ia simulaci\'on Monte Carlo (MCMC) para modelos multivariados.\\
\\
Para lograr expresar estos problemas con BUGS, explicado por sus creadores \cite{plummer2003jags}, se necesitan tomar en cuenta dos distribuciones:
\begin{itemize}
\item Una distribuci\'on que describa la probabilidad de estar en el estado $j$ en el tiempo $t$ dado que el sujeto estaba en el estado $i$ al tiempo $0$.
\item Una distribuci\'on de supervivencia que describa el tiempo en un estado absorbente, que bien, es conocida o censorada a la derecha.
\end{itemize}
La necesidad de estas distribuciones aunado a la necesidad de una herramienta que ayude a explorar modelos gr\'aficos es lo que da origen a JAGS. Es decir, el programa toma la descripci\'on del modelo general de probabilidad multivariado y regresa un muestreo de MCMC de la distribuci\'on posterior.\\
\\
De este modo, se establece no solo las bases para la inferencia y predicci\'on de futuras observaciones en base a la verosimilud extendida y la resoluci\'on de su funci\'on sino tambi\'en la implementaci\'on num\'erica de la misma. Una vez que se definieron estas herramientas, lo que resta es la adaptaci\'on del modelo a la ilustraci\'on con los datos, esto se explorar\'a m\'as adelante.