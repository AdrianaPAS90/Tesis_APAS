\chapter{Procesos de Duraci\'on Marcada}
\section{Introducci\'on}
En este cap\'itulo se tratar\'an los fundamentos de los modelos de duraci\'on y de duraci\'on marcada y su aplicaci\'on al tema de descripci\'on de evoluci\'on de una enfermedad y su tratamiento. Adem\'as de discutir algunas nociones de dependencia estoc\'astica relevantes, tales como independencia estoc\'astica, intercambiabilidad y estacionareidad que son vitales para realizar inferencia y predicci\'on de los datos.\\
\\
Despu\'es de que el proceso puntual sea definido m\'as adelante, se introducir\'a el concepto de variables latentes para poder construir las distribuciones de las variables observables, concepto que igualmente ser\'a definido en una secci\'on posterior. Para un individuo particular, estas variables conectan las observaciones a trav\'es del tiempo creando el modelo general de probabilidad que permite hacer inferencia y predicci\'on sobre futuras observaciones, a nivel individual. Tomando el modelo general de probabilidad, se elegir\'an las distribuciones que mejor se adaptan al comportamiento de las variables.\\
\\
Es importante remarcar que el desarrollo de los procesos puntuales ha estado unido al desarrollo de la estad\'istica actuarial y de seguros, \cite{daley2003} se refiere a las tablas de mortalidad como el primer estudio de procesos de intervalos, entre otros, los procesos de renovaci\'on \footnote{Seg\'un \cite{daley2003} es el estudio de la secuencia de intervalos entre reemplazos sucesivos de un componente que es susceptible a fallar y es reemplazado por un nuevo componente cada vez que ocurre un fallo.}, los procesos Markov y semi-Markov. Por lo que el uso de estos procesos como una forma de tarificar es solamente otra colaboraci\'on en la larga lista de estas dos disciplinas.
\\
\section{Definiciones y notaci\'on}
Para el objeto de este estudio consideramos el caso donde est\'a disponible la informaci\'on desagregada de un conjunto de individuos respecto a las transiciones de etapas de tratamiento para una enfermedad cr\'onico-degenerativa, cada etapa con la informaci\'on sobre sus respectivas  duraciones y costos. A su vez, cada uno de los individuos tiene asociadas covariables sociodemogr\'aficas, socioecon\'omicas y m\'edicas particulares; la inclusi\'on de estas covariables en el modelo es posible pero no est\'a dentro del alcance de esta tesis. Aunque las covariables asociadas a los individuos inciden en la trayectoria del padecimiento, estas relaciones son un tema a explorarse en un trabajo de investigaci\'on futuro.\\
\\
De este modo, podr\'iamos decir que tenemos individuos etiquetados con $i=1,...,I$, donde $I$ es el n\'umero total de individuos observados por un per\'iodo de tiempo con costos asociados a su padecimiento. El objetivo es no solo modelar y predecir la duraci\'on y el costo de las etapas de estos padecimientos por individuo, sino tambi\'en, introducir la estructura de dependencia entre \'estas con un significado intuitivo. De acuerdo a \cite{daley2003}, las relaciones de dependencia entre las variables pueden llegar a ser muy complejas, por lo que la especificaci\'on del modelo puede se puede tornar significativamente complicada.\\ 
\\
Entonces, supongamos que empezamos el estudio de un individuo $i$ en el tiempo $t_{i0}=0$, es decir, este es el tiempo en el que el individuo $i$ entra al panel de estudio. El momento final en el que el individuo $i$ est\'a en el estudio es $T_i$, es decir que el individuo permanece en el estudio en el intervalo $(t_{i0}, T_{i}]$, como horizonte calendario. Esto no quiere decir que no puedan ocurrir observaciones posteriores a $T_i$, sin embargo, \'estas ya no ser\'an consideradas parte del estudio; a esto se le conoce como datos con censura por la derecha.\\
\\
Seg\'un \cite{intropp}, un proceso puntual $N$ es una medida de probabilidad definida sobre un espacio m\'etrico separable $S$ tomando valores en los enteros no negativos $Z^+$. Con esta definici\'on general se puede decir que la medida $N(A)$ representa el n\'umero de puntos que cae en el subconjunto $A$ de $S$, \'esto puede interpretarse para dimensiones mayores en espacios abstractos. Sin embargo, si tomamos el conjunto $S$ como una dimensi\'on temporal podemos entender el caso particular de $N(t)$ como un proceso de conteo del n\'umero de puntos que ocurren antes del tiempo $t$.\\
\\
Sea $t_{ij} \in (t_{i0},T_i]$ el momento en el que ocurre el $j$-\'esimo cambio de tratamiento del $i$-\'esimo individuo, por lo que definimos la variable aleatoria $N(t_{ij})$ como el proceso de conteo que cuenta el n\'umero de cortes o cambios en el intervalo del individuo $i$ antes del cambio $j$; de este modo se puede expresar $N(T_i)$ como el n\'umero de cambios o de ocurrencias en todo el horizonte calendario del individuo $i$. Esto es una generalizaci\'on para cuando no se conoce la informaci\'on a utilizar o cuando el n\'umero de cambios en la trayectoria de un paciente tambi\'en es una variable aleatoria. Sin embargo, en la informaci\'on utilizada para la implementaci\'on de este trabajo, se trabaja con tiempos discretos y se conocen todos los cortes en los intervalos de trayectorias individuales.\\
\\
Dado que la muestra consiste en microcostos a trav\'es del tiempo de un individuo $i$, decimos que a cada $t_{ij}$ se le asocia la variable costo de tratamiento; es decir, a cada momento en que ocurre un cambio de tratamiento le corresponde un nuevo precio de tratamiento $p_{ij}$. De este modo, para cualquier $i$ tenemos una sucesi\'on de variables asociadas $\{t_{i1},p_{i1}\},\{t_{i2},p_{i2}\},...,\{t_{ik},p_{ik}\}$, donde $k$ indica la variable de cambio de diagn\'ostico. De este modo la sucesi\'on de variables es una colecci\'on aleatoria de puntos en un espacio con una marca asociada a cada punto, as\'i ya se pueden modelar los datos como en un proceso puntual marcado.\\
\\
\cite{daley2003} definen el proceso puntual marcado como un proceso localizado en un espacio m\'etrico completamente separable \footnote{Un espacio m\'etrico completo $\chi$ se dice que es separable si existe un subconjunto numerable $D$ tal que los elementos de $D$ pueden usarse para aproximar cualquier elemento de $\chi$. (Ver \cite{schervish2012theory})} $\chi$ y las marcas en otro espacio m\'etrico completamente separado $\kappa$, entonces $\{(\chi_i,\kappa_i)\}$ en $\chi \times \kappa$ es un proceso puntual marcado con la propiedad adicional de que el proceso que se desarrolla en una dimensi\'on temporal, $N(t)$ es a su vez un proceso puntual.\\
\\
Desde un punto de vista pr\'actico, para un solo individuo, deseamos caracterizar,
\begin{align}
P(t_{i1},...,t_{in_i},p_{i1},...,p_{in_i}|N(T_i)=n_i)
\end{align}
\\
Es decir, la funci\'on de distribuci\'on conjunta del tiempo de ocurrencia de los eventos y los precios asociados condicionados por la variable aleatoria del n\'umero de eventos en el intervalo $(t_{i0},T_i]$. Sin embargo, dado que al usar las variables en sus valores absolutos estas pueden dar saltos muy altos entre si, es recomendable el uso de variables alternas.\\
\\
De acuerdo a \cite{daley2003}, al tener un proceso puntual o de conteo $N(\cdot)$, se puede establecer una relaci\'on entre el proceso de conteo y los intervalos si definimos $t_j(N)=inf\{t:N(t) \geq j\}$, por lo tanto, se define el siguiente intervalo $\tau_j(N)=t_j(N)-t_{j-1}(N)$, donde $\sum_{j=1}^\infty \tau_i=\infty$. Esta definici\'on es an\'aloga a aquella que define $t_j$ como el $j$-\'esimo cambio de tratamiento para un solo individuo y los intervalos como las duraciones; el concepto de intervalos se hace extensivo para los costos de la siguiente manera para un solo individuo $i$:
\begin{itemize}
\item $D_{ij}=t_{ij}-t_{ij-1}$, donde $D_{ij}$ es la duraci\'on entre los tiempos de ocurrencia de cada individuo.
\item $C_{ij}=p_{ij}-p_{ij-1}$, donde $C_{ij}$ representa el costo, es decir, la diferencia entre los precios en cada tiempo de ocurrencia de cada individuo.
\end{itemize}
\begin{figure}[h!]
\begin{center}
\begin{picture}(200,100)
\put(0,0){\vector(1,0){200}} \put(0,0){\vector(0,1){100}}
\multiput(-5,20)(0,20){4}{\line(10,0){10}}
\multiput(20,-5)(35,0){5}{\line(0,10){10}}
\put(0,20){\line(10,0){20}}
\put(20,40){\line(10,0){35}}
\put(55,60){\line(10,0){35}}
\put(90,80){\line(10,0){35}}
\put(20,0){\makebox(0,-15){$t_{i1}$}}
\put(55,0){\makebox(0,-15){$t_{i2}$}}
\put(90,0){\makebox(0,-15){$t_{i3}$}}
\put(120,0){\makebox(0,-15){$t_{i4}$}}
\put(142,0){\makebox(0,-15){$\cdots$}}
\put(160,0){\makebox(0,-15){$t_{ik}$}}
\put(0,20){\makebox(-25,0){$p_{i1}$}}
\put(0,40){\makebox(-25,0){$p_{i2}$}}
\put(0,60){\makebox(-25,0){$p_{i3}$}}
\put(0,75){\makebox(-25,0){$\vdots$}}
\put(0,85){\makebox(-25,0){$p_{ik}$}}
\put(20,0){\dashbox{3}(0,20){}}
\put(30,0){\makebox(0,20){$C_{i1}$}}
\put(20,20){\dashbox{3}(0,20){}}
\put(30,20){\makebox(0,20){$C_{i2}$}}
\put(55,40){\dashbox{3}(0,20){}}
\put(65,40){\makebox(0,20){$C_{i3}$}}
\put(90,60){\dashbox{3}(0,20){}}
\put(100,60){\makebox(0,20){$C_{ik}$}}
\put(0,-15){\dashbox{3}(13,0){}}
\put(0,-25){\makebox(20,0){$D_{i1}$}}
\put(25,-15){\dashbox{3}(23,0){}}
\put(28,-25){\makebox(20,0){$D_{i2}$}}
\put(62,-15){\dashbox{3}(21,0){}}
\put(60,-25){\makebox(20,0){$D_{i3}$}}
\put(97,-15){\dashbox{3}(16,0){}}
\put(94,-25){\makebox(20,0){$D_{i4}$}}
\put(128,-15){\dashbox{3}(25,0){}}
\put(130,-25){\makebox(20,0){$D_{ik}$}}
\end{picture}
\end{center}
.\\
\caption{Trayectorias del individuo $i$.}
\end{figure}
.\\
\\
Es importante mencionar, como lo hacen \cite{daley2003}, que hay una correspondencia de uno a uno entre las distribuciones de probabilidad del proceso puntual y las distribuciones de los intervalos, es por eso que el modelo inicial de probabilidad con las variables de tiempos y precios, les corresponde una medida de probabilidad distinta a aquella de las variables de duraciones y costos. De este modo, la medida de probabilidad $Q(t_{i1},...,t_{in_i},p_{i1},...,p_{in_i}|N(T_i)=n_i)$ y la medida de probabilidad $P(D_{i1},...,D_{in_i},C_{i1},...,C_{in_i}|N(T_i)=n_i)$ est\'an mutuamente relacionadas pues tienen el mismo punto de partida siendo \'este la primera realizaci\'on del individuo.
%\begin{align}
%Q(t_{i1},...,t_{in_i},p_{i1},...,p_{in_i}|N(T_i)=n_i) \cong P(D_{i1},...,D_{in_i},C_{i1},...,C_{in_i}|N(T_i)=n_i)
%\end{align}
Esto quiere decir que calcular la funci\'on de distribuci\'on conjunta de los tiempos de ocurrencia y los precios asociados a \'estos es an\'alogo a a calcular la funci\'on de distribuci\'on conjunta de las duraciones y los costos asociados condicionados a la variable aleatoria del n\'umero de eventos en el intervalo de tiempo. As\'i pasamos de un proceso puntual marcado a uno de duraci\'on marcada.\\
\\
De este modo, quedan definidas las variables aletorias del modelo que se pueden observar, siendo \'estas $D_{ik}$ para la duraci\'on $k$-\'esima del $i$-\'esimo individuo y $C_{ik}$ para el costo $k$-\'esimo del $i$-\'esimo individuo y la distribuci\'on de probabilidad indicada para el mismo. Por otro lado, en la aplicaci\'on del modelo tenemos las variables aleatorias observables seg\'un la informaci\'on existente, las cuales tendr\'an la siguiente notaci\'on: $d_{ik}$ como la $k$-\'esima duraci\'on observada para el $i$-\'esimo individuo y $c_{ik}$ como el $k$-\'esimo costo observado para el $i$-\'esimo individuo. De igual modo, con las variables observadas sabemos que $N(T_i)=n_i$, \'este valor es fijo pues ya fue observado y relativo a cada individuo.\\
\\
As\'i pues, el modelo de probabilidad consiste en dos variables observables, duraci\'on y costo. La relaci\'on entre estas dos variables para un individuo $i$ es una de las siguientes opciones,\\
\\
Las variables son independientes entre s\'i, es decir,
\begin{eqnarray*}
P(d_{i1},...,d_{in_i},c_{i1},...,c_{in_i}|N(T_i)=n_i)&=&P(d_{i1},...,d_{in_i}|N(T_i)=n_i)\\
&\times& P(c_{i1},...,c_{in_i}|N(T_i)=n_i)
\end{eqnarray*}
\\
O las variables de duraci\'on y costos no son independientes entre s\'i. En este caso, necesitamos determinar la estructura de dependencia entre las variables que puede expresarse de las siguientes dos formas,\\
\\
Puede ser que las duraciones dependen de los costos, o bien, en el contexto del proceso puntual marcado, que los puntos dependen de las marcas. Es decir,
\begin{multline*}
	P((d_{i1},c_{i1}),...,(d_{in_i},c_{in_i})|N(T_i)=n_i)= \\
	P(d_{i1},...,d_{in_i}|N(T_i)=n_i,c_{i1},...,c_{in_i})\times P(c_{i1},...,c{in_i}|N(T_i)=n_i)
\end{multline*}

O bien, los costos dependen de las duraciones, esto quiere decir, que en el contexto del proceso puntual marcado, las marcas dependen de los puntos. Se observa una estructura de dependencia similar en el art\'iculo de \cite{engle1998autoregressive}, donde se observa tipo de estructura de dependencia en el contexto de transacciones financieras. Esta estructura de dependencia se puede expresar como,
	\begin{multline*}
     P((d_{i1},c_{i1}),...,(d_{in_i},c_{in_i})|N(T_i)=n_i)=\\
     P(c_{i1},...,c_{ik}|N(T_i)=n_i,d_{i1},...,d_{in_i})\times P(d_{i1},...,d_{in_i}|N(T_i)=n_i)
    \end{multline*}	

En este caso, los precios dependen del cambio de tratamiento, de manera an\'aloga, la variable costo est\'a asociada a la variable de duraci\'on. Es decir, que aunque la marca se localice en otro espacio m\'etrico, \'esta sigue anclada al proceso puntual primario, el que cuenta el n\'umero de ocurrencias en el espacio temporal.\\
\\
Por la estructura de construcci\'on del modelo este se puede pensar,para un solo momento $k$ en el tiempo de un individuo $i$, como
\begin{align}
P(d_{ik},c_{ik}|N(t)) = P(c_{ik}|d_{ik})P(d_{ik})
\end{align}
Este proceso es replicable para cada momento de la trayectora y cada individuo en la muestra.
\section{Propiedades de los Procesos de Duraci\'on Marcada}
Una vez que hemos definido qu\'e es el proceso de duraci\'on y de duraci\'on marcada y c\'omo es que los datos que tenemos para este estudio se adaptan a este modelo, necesitamos especificar las propiedades que van a hacer posible la inferencia y la predicci\'on. Estas propiedades son la independencia, la intercambiabilidad y, principalmente, la estacionareidad.
\subsubsection{Independencia}
En una concepci\'on tradicional, \cite{resnickpath} define la independencia de un n\'umero finito de eventos como:\\
\begin{defi}
Los eventos $X_1$, ... , $X_n$ (n$\geq$ 2) son independientes si
\begin{align*}
P\left(\bigcap_{i \in I} X_i\right) = \prod_{i \in I} P(X_i), \qquad I \subset\{1,...,n\}
\end{align*}
\end{defi}
Los eventos son independientes si la probabilidad de la intersecci\'on de estos eventos o la probabilidad conjunta de los eventos es igual a la multiplicaci\'on de la probabilidad de los mismos.\\
\\
An\'alogamente, podemos hacer la definici\'on de independencia estoc\'astica para el proceso de duraci\'on marcada. Recordemos que tenemos la funci\'on de probabilidad conjunta de las duraciones y los costos, por lo que la independencia en el proceso es:
\begin{eqnarray*}
P(d_{i1},c_{i1},...,d_{in_i},c_{in_i}|N(T_i)=n_i)= \prod_{j=1}^{n_i} P(d_{ij},c_{ij})
\end{eqnarray*}
En este caso, la \'unica diferencia reside en el hecho de que el n\'umero de funciones de probabilidad a multiplicar es a su vez una variable aleatoria, la cual se encarga de contar los cambios en el costo de tratamiento en el tiempo. En la implementaci\'on ya sabemos el valor observado de la variable aleatoria de conteo como $n_i$, como se puede ver en la segunda igualdad. El supuesto de independencia es \'util para la inferencia de futuras observaciones.
\subsubsection{Intercambiabilidad}
Otra propiedad muy importante para la inferencia y predicci\'on de variables en un proceso de duraci\'on marcada es la intercambiabilidad que, de acuerdo a \cite{hahn2012exchangeable}, se define como:
\begin{defi}
Una sucesi\'on de variables numerable o contable $(X_j)_{j=1}^{\infty}$ es intercambiable si para cada operador de permutaci\'on $\sigma(\cdot)$ de $\{1,...,n\}$, para toda $n<\infty$ 
\begin{align}
P(X_1,X_2,...,X_n)=P(X_{\sigma(1)},X_{\sigma(2)},...,X_{\sigma(n)}) \nonumber
\end{align}
\end{defi}
Si la sucesi\'on de variables es independiente e id\'enticamente distribuida entonces es intercambiable. El concepto de intercambiabilidad est\'a muy relacionado con la independencia, pues la independencia es un caso particular de la intercambiabilidad.\\
\\
Para poder entender mejor la propiedad podemos citar el Teorema de de Fenetti(1937) que nos dice que una sucesi\'on infinita de variables aleatorias intercambiables $\bar{X}=(X_1,X_2,...)$ es una mezcla de variables condicionalmente independientes e id\'enticamente distribuidas (i.i.d). Esto es, que existe un espacio de probabilidad $(U,\Theta)$ tal que
\begin{align*}
P(\bar{X} \in B)=\int_U P(\bar{X}(u) \in B) \Theta(du)
\end{align*}
donde $\bar{X}(u)=(X_1(u),X_2(u),...)$ es una secuencia de variables aleatorias i.i.d. y $\Theta(\cdot)$ es una medida de probabilidad.\\
\\
Esto se puede adaptar al proceso de duraci\'on marcada correspondiente a este an\'alisis de la siguiente manera, tomando el Teorema de Fenetti
\begin{eqnarray*}
P(d_{i1},c_{i1},...,d_{in_i},c_{in_i}|N(T_i)=n_i)&=&\int_\Theta \prod_{j=1}^{N(T_i)} P(d_{ij},c_{ij}|\theta) \pi(\theta) d(\theta)\\
&=& \int_\Theta \prod_{j=1}^{n_i} P(d_{ij},c_{ij}|\theta) \pi(\theta) d(\theta)
\end{eqnarray*}
donde $\theta$ es una variable aleatoria no observable y $\pi(\theta)$ es una medida de probabilidad com\'un a todas las variables aleatorias. Es decir, que a lo postulado en el apartado de independencia le agregamos la variable no observable con su respectiva medida de probabilidad, sobre cuyo espacio de probabilidad est\'a definida la integral. La variable no observable com\'un a todas las variables aleatorias es un tema que se posteriormente se desarrollar\'a con mayor profundidad. De igual modo que en la contextualizaci\'on de la propiedad de independencia, en este caso, conocemos el valor observado de $N(T_i)$ como $n_i$ fijo y \'unico para cada individuo.
\subsubsection{Estacionariedad}
Una vez que han sido definidas la independencia y la intercambiabilidad faltar\'ia definir la estacionariedad para poder hacer predicciones sobre futuras observaciones, cuando el orden de las observaciones es relevante en el modelo.\\
\\
De manera intuitiva, podemos definir la estacionariedad en un proceso de duraci\'on cuando la funci\'on de probabilidad conjunta del proceso no cambia cuando es \'esta es desplazada en el tiempo, lo cual indicar\'ia que lo importante es la longitud de los intervalos, no la localizaci\'on de los mismos. Sin embargo, de una manera m\'as t\'ecnica, \cite{daley2003} definen la estacionariedad en un proceso como:
\begin{defi}
Un proceso puntual es estacionario por intervalos cuando para cada $r=1,2,...$ y todos los enteros $i_i,...,i_r$ , la distribuci\'on conjunta de $\{\tau_{i_{1+k}},...,\tau_{i_{r+k}}\}$ no depende de $k$ ($k=0, \pm 1, ...$).
\end{defi}
Esto implicar\'ia que el orden de las observaciones importa y que las observaciones pasadas ayudan a construir la variable aleatoria. Es decir que con una sucesi\'on de variables de duraciones para un solo individuo $\bar{D}=(D_1,...,D_n)$ tendr\'iamos que,
\begin{eqnarray*}
P(D_n,...,D_1)&=&P(D_n|D_{n-1},...,D_1)\times P(D_{n-1}|D_{n-2},...,D_1)\times \cdots\\
               &\times& P(D_2|D_1)\times P(D_1)
\end{eqnarray*}	
As\'i si la variable aleatoria depende de su historia, podr\'iamos entonces predecir observaciones futuras. Es decir, que si para toda $s \geq 0$
\begin{multline*}
P(D_{n+1},D_n,...,D_1)=P(D_{n+s+1},...,D_{s+1})\\
\Rightarrow P(D_{n+1}|D_n,...,D_1) = P(D_{n+s+1}|D_{n+s},...,D_{s+1})
\end{multline*}
Esto se prueba por inducci\'on de la siguiente manera,
\begin{proof}
Para n=1 se cumple que,\\
\begin{align*}
P(D_1,D_2)=P(D_{1+s},D_{2+s})
\end{align*}
Luego,\\
\begin{align*}
P(D_2|D_1)P(D_1)=P(D_{2+s}|D_{1+s})P(D_{1+s})
\end{align*}
Pero por hip\'otesis, $P(D_1)=P(D_{1+s})$\\
$\Rightarrow P(D_2|D_1)=P(D_{2+s}|D_{1+s})$\\
\\
Ahora, supongamos que
\begin{align*}
P(D_{n+1},...,D_1) = P(D_{1+s},...,D_{n+s+1}) \quad \forall n
\end{align*}
Y,
\begin{align*}
P(D_{n+1}|D_n,...,D_1)=P(D_{n+s+1}|D_{n+s},...,D_{1+s})
\end{align*}
Para $n+1$ sabemos que,
\begin{align*}
P(D_1,...,D_{n+1},D_{n+2})=P(D_{1+s},...,D_{n+s+1},D_{n+s+2})
\end{align*}
Luego,
\begin{multline*}
P(D_{n+2}|D_{n+1},...,D_1)\times P(D_{n+1}|D_n,...,D_1)\times,...,\times P(D_2|D_1)P(D_1) = \\
= P(D_{n+s+2}|D_{n+s+1},...,D_{1+s}) \times P(D_{n+s+1}|D_{n+s},...,D_{1+s}) \times,...,\times\\
P(D_{2+s}|D_{1+s})P(D_{1+s})
\end{multline*}
As\'i, por hip\'otesis,
\begin{align*}
P(D_{n+s+2}|D_{n+s+1},...,D_{1+s})=P(D_{n+2}|D_{n+1},...,D_1)
\end{align*}
\end{proof}
De este modo, para el proceso de duraci\'on marcada la estacionariedad, junto con la noci\'on desarrollada en la ecuaci\'on $(3)$ sobre la relaci\'on de las marcas con el proceso de duraci\'on, se podr\'ia plantear, para un individuo $i$, como
\begin{eqnarray*}
P(d_{i1},c_{i1},...,d_{in_i},c_{in_i}|N(T_i)=n_i)&=&P(d_{i1},c_{i1})\\
&\times& \prod_{j=2}^{N(T_i)} P(d_{ij},c_{ij}|d_{ij-1},c_{ij-1})\\
\\
                             &=&P(c_{i1}|d_{i1})P(d_{i1}) \times\\
                             &\times& \prod_{j=2}^{N(T_i)} P(d_{ij}|d_{ij-1})P(c_{ij}|d_{ij},c_{ij-1}) \\
                             \\
       &=& P(c_{i1}|d_{i1})P(d_{i1}) \times\\
       &\times& \prod_{j=2}^{n_i} P(d_{ij}|d_{ij-1})P(c_{ij}|d_{ij},c_{ij-1})                      
\end{eqnarray*}
Lo que quiere decir que la funci\'on conjunta de probabilidad se puede definir con base a observaciones pasadas. De igual modo que con las propiedades pasadas, en la implementaci\'on conocemos el valor observado de $N(T_i)$ como $n_i$ fijo y \'unico para cada indiviudo. \\
\\
Citando a \cite{daley2003} el proceso puntual marcado es estacionario si la estructura de probabilidad del proceso no cambia a pesar de los cambios que puedan existir en el espacio m\'etrico $\chi$, es decir, en el espacio m\'etrico del proceso de conteo primario o el proceso de conteo que se desarrolla en la dimensi\'on temporal. De acuerdo a lo desarrollado en la secci\'on anterior se concluye que tanto el proceso primario como el Proceso Puntual Marcado (PPM), ambos son estacionarios, lo que permitir\'ia la inferencia sobre el mismo.\\
\\
Una vez que nuestro modelo de duraci\'on marcada cumple las propiedades descritas en esta secci\'on podemos empezar a hacer inferencia sobre las variables y predecir las observaciones futuras. En la siguiente secci\'on, desarrollaremos un modelo complementario de variables latentes que terminar\'ia de conectar la idea de la variable no observable presentada en el concepto de intercambiabilidad con el resto de la sucesi\'on.

\section{Construcci\'on de Procesos v\'ia Variables Latentes}
Como est\'a formulado al final de la secci\'on pasada, el modelo general de probabilidad para un solo individuo $i$ bajo estacionareidad con valor observado, \'unico y fijo para la variable $N(T_i)$ ($N(T_i)=n_i$), lo escribimos como
\begin{align*}
P((d_{ij},c_{ij})_{j=1}^{n_i})= P(c_{i1}|d_{i1})P(d_{i1}) \prod_{j=2}^{n_i} P(d_{ij}|d_{ij-1})P(c_{ij}|d_{ij},c_{ij-1})
\end{align*}
Se puede observar en el modelo general que, gracias a la estacionareidad del mismo, es necesario conocer las distribuciones de una variable en un momento $j$ condicionada a la misma variable en el momento $j-1$. Es decir, se necesitan conocer las distribuciones $f(d_{ij}|d_{ij-1})$ y $f(c_{ij}|c_{ij-1},d_{ij})$. El m\'etodo de para conocer estas distribuciones es an\'alogo entre ambas, por lo que se desarrollar\'a el proceso en la distribuci\'on de las duraciones para despu\'es extenderla a aquella de los costos.\\
\\
En este modelo se tienen las variables aleatorias observables que son las duraciones y los costos, pues son las que se pueden obtener de la informaci\'on disponible. Para lograr construir estas distribuciones se supone que no se conoce la relaci\'on entre las variables observables, en este caso las variables observables se refieren a las duraciones, a trav\'es del tiempo. Para efecto de la construcci\'on del modelo se supone tambi\'en que existe una variable no observable, o latente, que conecta a las observaciones.
\subsection{Modelo Latente de Markov}
Tomando como base el procedimiento propuesto por \cite{pitt2002constructing}, la distribuci\'on $f(d_{ij}|d_{ij-1})$ se puede reescribir como $f_{Y|Z}(y|z)$ siendo $Y=d_{ij}$ y $Z=d_{ij-1}$. Esta distribuci\'on a su vez se puede reescribir como
\begin{align*}
f_Y(y)=\int f_{Y|Z}(y|z)f_Y(z)dz
\end{align*}
\\
Para lograr la conexi\'on entre las variables observables se necesita agregar otra variable, que le llamaremos latente, a esta distribuci\'on por lo que consideramos ahora las distribuciones de trancisi\'on como
\begin{align*}
f_{Y|Z}(y|z)=\int f_{Y|\Theta}(y|\theta)f_{\Theta|Z}(\theta|z)d\lambda(\theta)
\end{align*}
donde $\lambda(\theta)$ es una medida de probabilidad correspondiente a la variable latente.\\
\\
Regresando a la notaci\'on original, la anterior distribuci\'on se reescribe como,
\begin{align*}
f_{D_{ij}|D_{ij-1}}(d_{ij}|d_{ij-1})=\int f_{D_{ij}|\Theta}(d_{ij}|\theta)f_{\Theta|D_{ij-1}}(\theta|d_{ij-1})d\lambda(\theta)
\end{align*}
El punto crucial para asegurar la distribuci\'on de trancisi\'on es construir una distribuci\'on conjunta $f_{D_{ij},\Theta}(d_{ij},\theta)$, tal que las densidades condicionales sean $f_{D_{ij}|\Theta}(d_{ij}|\theta)$ y $f_{\Theta|D_{ij-1}}(\theta|d_{ij-1})$ y con una distribuci\'on marginal $f_{D_{ij}}(d_{ij})$. Es decir, el proceso de trancisi\'on se logra mediante el proceso de la variable latente, que aunque no es observable, este es conocido.
\subsection{Modelo Oculto de Markov}
Seg\'un lo desarrollado en la secci\'on anterior, vemos que para conocer la distribuci\'on de una observaci\'on condicionada a la observaci\'on anterior se necesita introducir una variable no observable o latente. La introducci\'on de esta variable se puede hacer mediante el Modelo Oculto de Markov, que de acuerdo con las nociones expuestas por \cite{ghahramani2001introduction}, es un modelo donde la variable observable $d_{ij}$, en este caso la $j$-\'esima duraci\'on del individuo $i$ y la variable no observable $\theta_{ij}$ son independientes y la variable no observable cumple la propiedad markoviana. Es decir, que dado el valor de $\theta_{ij-1}$, el estado actual $\theta_{ij}$ es independiente de todos aquellos estados previos a $j-1$. La funci\'on de distribuci\'on conjunta ser\'ia
\begin{align*}
P((d_{ij},\theta_{ij})_{j=1}^{n_i})=P(d_{i1}|\theta_{i1})P(\theta_{i1})\prod_{j=2}^{n_i} P(d_{ij}|\theta_{ij})P(\theta_{ij}|\theta_{ij-1})
\end{align*}
Es decir,\\
\begin{figure}[h!]
\begin{center}
\begin{picture}(200,50)
\put(0,50){$d_{i1}$}
\put(30,50){$d_{i2}$}
\put(60,50){$d_{i3}$}
\put(110,50){$\ldots$}
\put(150,50){$\ldots$}
\put(200,50){$d_{in_i}$}
\put(5,10){\vector(0,1){35}}
\put(35,10){\vector(0,1){35}}
\put(65,10){\vector(0,1){35}}
\put(205,10){\vector(0,1){35}}
\put(0,0){$\theta_{i1}$}
\put(30,0){$\theta_{i2}$}
\put(60,0){$\theta_{i3}$}
\put(110,5){$\ldots$}
\put(150,5){$\ldots$}
\put(200,0){$\theta_{in_i}$}
\put(10,5){\vector(1,0){20}}
\put(40,5){\vector(1,0){20}}
\put(70,5){\vector(1,0){20}}
\put(180,5){\vector(1,0){20}}
\end{picture}
\end{center}
\caption{Representaci\'on gr\'afica de un Modelo Oculto de Markov.}
\end{figure}
\\
El Modelo Oculto de Markov es un modelo muy flexible, seg\'un \cite{ghahramani2001introduction}, puede ser utilizado para modelar cualquier distribuci\'on con un n\'umero infinito de componentes y con las adecuaciones correspondientes se pueden modelar un sinn\'umero de de problemas din\'amicos no-lineales; esta misma flexibilidad es lo que le resta fiabilidad a la inferencia. Aunado a esto, el modelo se basa en la relaci\'on existente entre los estados en el tiempo del par\'ametro, es decir, $P(\theta_{ij}|\theta_{ij-1})$, esta relaci\'on no es conocida en el problema de estudio del presente trabajo por lo que el Modelo Oculto de Markov no es el que mejor se adapta.\\
\\
Dado que el Modelo Oculto de Markov descrito no es el adecuado para el caso de estudio de este trabajo, pero se necesita un modelo que integre variables latentes para explicar las relaciones entre las variables observables. As\'i pues, se toma como base un caso particular del Modelo Oculto de Markov y el Modelo Latente de Markov: los Modelos Din\'amicos Lineales descritos por \cite{harrison1999bayesian}. De este modo, el proceso de la variable latente para el caso de las duraciones de un individuo $i$, ser\'ia\\
\\
Ecuaci\'on de Observaci\'on: $d_{ij}=\theta_{ij} + \epsilon_{ij}$\\
\\
Ecuaci\'on de Sistema: $\theta_{ij}=\theta_{ij-1}+ \nu_{ij}$\\
\\
Donde los errores $\epsilon_{ij}$ y $\nu_{ij}$ son mutuamente independientes. El modelo din\'amico lineal es an\'alogo para las variables de duraci\'on y costos. Adem\'as de que no se conoce la distribuci\'on marginal de las observaciones.\\
\subsection{Comparaci\'on entre Modelos Latentes y Ocultos de Markov}
Siguendo con el argumento propuesto por \cite{pitt2002constructing}, necesitamos una variable latente sobre la cual se pueda hacer inferencia. Haciendo el s\'imil con los modelos din\'amicos lineales, incorporando la variable latente para la variable de duraci\'on,\\
\\
Ecuaci\'on de Observaci\'on: $d_{ij}|\theta_{ij} \sim f_{d|\Theta}(\cdot|\theta_{ij})$\\
\\
Ecuaci\'on de Sistema: $\theta_{ij}|d_{ij-1} \sim f_{\Theta|d}(\cdot|d_{ij-1})$\\
\\
De este modo, podemos definir la probabilidad marginal como,
\begin{align*}
P(d_{ij})=\int p(d_{ij}|d_{ij-1})p(d_{ij-1})=\int p(d_{ij}|\theta_{ij})p(\theta_{ij}|d_{ij-1})d\theta_{ij}
\end{align*}
Una vez que tenemos el modelo para la variable de las duraciones, lo hacemos extensivo para los costos. De este modo, el proceso de variables latentes para un individuo $i$ quedar\'ia,\\
\\
Ecuaci\'on de Observaci\'on: $c_{ij}|\gamma_{ij} \sim f_{c|\gamma}(\cdot|\gamma_{ij})$\\
\\
Ecuaci\'on de Sistema: $\gamma_{ij}|c_{ij-1} \sim f_{\gamma|c}(\cdot|c_{ij-1})$\\
\\
De manera an\'aloga, podemos definir la probabilidad marginal de los costos como,
\begin{align*}
P(c_{ij})=\int p(c_{ij}|c_{ij-1},d_{ij})p(c_{ij-1})=\int p(c_{ij}|\gamma_{ij},d_{ij})p(\gamma_{ij}|c_{ij-1},d_{ij})d\gamma_{ij}
\end{align*}
Dado que el Modelo Oculto de Markov no necesariamente es estacionario afectando as\'i la capacidad inferencial del mismo, el modelo que se construye a trav\'es de las estructuras de dependencia con la variable latente que se acabande definir, es estacionario por construcci\'on y es capaz de modelar la observaci\'on actual en relaci\'on a la observaci\'on anterior. Tomando solamente la variable duraci\'on del individuo $i$ junto con su par\'ametro $\theta$, la representaci\'on gr\'afica de ambos modelos se compara del siguiente modo,\\
\begin{figure}[h!]
\begin{center}
\begin{picture}(200,50)
\put(0,50){$d_{i1}$}
\put(50,50){$d_{i2}$}
\put(100,50){$\ldots$}
\put(200,50){$d_{in_i}$}
\put(5,15){\vector(0,1){30}}
\put(55,15){\vector(0,1){30}}
\put(205,15){\vector(0,1){30}}
\put(0,5){$\theta_{i1}$}
\put(50,5){$\theta_{i2}$}
\put(100,5){$\ldots$}
\put(200,5){$\theta_{in_i}$}
\put(15,5){\vector(1,0){35}}
\put(65,5){\vector(1,0){35}}
\put(170,5){\vector(1,0){30}}
%\put(95,10){\vector(-3,1){90}}
%\put(95,10){\vector(-1,1){37}}
%\put(95,10){\vector(3,1){110}}
\color{green}{\put(15,45){\vector(1,-1){30}}}
\put(58,15){\vector(0,1){30}}
\put(65,45){\vector(1,-1){30}}
\put(165,45){\vector(1,-1){30}}
\put(210,15){\vector(0,1){30}}
%\put(95,15){\vector(-3,1){85}}
%\put(95,15){\vector(-1,1){32}}
%\put(95,15){\vector(3,1){105}}
\end{picture}
\end{center}
\caption{Comparaci\'on entre un Modelo Oculto de Markov y un modelo de variables latentes}
\end{figure}
\\
Las flechas negras representan un Modelo Oculto de Markov, donde la relaci\'on con el estado anterior se presenta solamente en los par\'ametros $\theta_{ij}|\theta_{ij-1}$; mientras que las flechas verdes representan el modelo construido donde los observaciones est\'an condicionadas al par\'ametro y el par\'ametro est\'a condicionado por la observaci\'on anterior. La diferencia entre estos modelos reside, en su mayor parte, en que el modelo de variables latentes inducido por \cite{pitt2002constructing} es estacionario por construcci\'on, adem\'as de que se pueden definir las distribuciones condicionales y marginales; mientras que en el modelo oculto de markov no.\\
\\
Ahora bien, utilizando las relaciones entre las variables observables y latentes, el proceso de trancisi\'on para una observaci\'on en el modelo general de probabilidad para un individuo $i$ con procesos de variables latentes se escribe asegurando la estacionariedad desde la construcci\'on,
\begin{eqnarray*}
P(c_{ij},d_{ij}|c_{ij-1},d_{ij-1}) &=&\int P(c_{ij},d_{ij}|\gamma,\theta)P(\gamma,\theta|c_{ij-1},d_{ij-1})\\
&=&\int \int F(c_{ij},d_{ij}|\gamma,\theta)\pi(\gamma|d_{ij},c_{ij-1})\pi(\theta|d_{ij-1})\\
&=&\int \int F(c_{ij}|\gamma,d_{ij}) F(d_{ij}|\theta)\pi(\gamma|d_{ij},c_{ij-1})\pi(\theta|d_{ij-1})\\
&=&\int F(c_{ij}|\gamma,d_{ij})\pi(\gamma|d_{ij},c_{ij-1}) \int F(d_{ij}|\theta)\pi(\theta|d_{ij-1})\\
&=&P(c_{ij}|d_{ij},c_{ij-1})P(d_{ij}|d_{ij-1})
\end{eqnarray*}
De este modo, el modelo general de la probabilidad para un individuo $i$ con la variable aleatoria $N(T_i)$ observada con valor $n_i$ fijo y \'unico para cada individuo, es
\begin{eqnarray*}
P((d_{ij},c_{ij})_{j=1}^{n_i}|N(T_i)=n_i)&=& P(c_{i1}|d_{i1})P(d_{i1}) \prod_{j=2}^{n_i} P(c_{ij}|d_{ij},c_{ij-1})P(d_{ij}|d_{ij-1})\\%\int f(d_1|\theta_1)f(\theta_1)d\theta_1 \int f(c_1|d_1,\gamma_1 ) f(\gamma_1)d\gamma_1 \times \nonumber \\ 
%&& %\times \prod_{j=2}^{N(t)} \int f(d_j|\theta_j) f(\theta_j|d_{j-1}) d\theta_j \times \nonumber\\
%&&%\times \int f(c_j|d_j,\gamma_j)f(\gamma_j|c_{j-1})d\gamma_j \times P(N(t)=k) \nonumber
\end{eqnarray*}
Este es el modelo general de probabilidad del proceso puntual marcado de las duraciones y costos de las enfermedades cr\'onico degenerativas. Al introducir las variables latentes se construyen funciones de trancisi\'on m\'as s\'olidas, tomando en cuenta los par\'ametros que influyen en el mismo proceso.\\
\\
Como se ve en el modelo general de probabilidad, la estructura de dependencia con las variables latentes y como, aunque los valores de estas variables no son observables, son influenciados por los valores de las variables observables. Esta estructura de dependencia, seg\'un \cite{gelman2014bayesian}, puede denorminarse como un modelo jer\'arquico con resultados observables condicionados a ciertos par\'ametros, los cuales, a su vez, est\'an dados como variables aleatorias definidos a su vez con otros par\'ametros. Es decir, para un individuo $i$, \\
.\\
\\
.\\
\\
\begin{figure}[h!]
\begin{center}
\begin{picture}(200,100)
\put(0,100){$c_{i1}$}
\put(40,100){$c_{i2}$}
\put(80,100){$\ldots$}
\put(200,100){$c_{in_i}$}
\put(0,65){$d_{i1}$}
\put(40,65){$d_{i2}$}
\put(80,65){$\ldots$}
\put(200,65){$d_{in_i}$}
\put(0,35){$\gamma_{i1}$}
\put(40,35){$\gamma_{i2}$}
\put(80,35){$\ldots$}
\put(200,35){$\gamma_{in_i}$}
\put(140,100){$\ldots$}
\put(140,65){$\ldots$}
\put(140,35){$\ldots$}
\put(140,0){$\ldots$}
\put(0,0){$\theta_{i1}$}
\put(40,0){$\theta_{i2}$}
\put(80,0){$\ldots$}
\put(200,0){$\theta_{in_i}$}
\put(5,75){\vector(0,1){20}}
\put(45,75){\vector(0,1){20}}
\put(205,75){\vector(0,1){20}}
\put(10,93){\vector(1,-2){25}}
\put(50,93){\vector(1,-2){25}}
\put(170,98){\vector(1,-2){27}}
\put(10,60){\vector(1,-2){25}}
\put(50,60){\vector(1,-2){25}}
\put(170,60){\vector(1,-2){27}}
\qbezier(0,35)(-25,65)(0,100)
\put(-4,93){\vector(2,3){5}}
\qbezier(40,35)(5,65)(40,100)
\put(36,93){\vector(2,3){5}}
\qbezier(200,35)(165,65)(200,100)
\put(196,93){\vector(2,3){5}}
\qbezier(0,5)(-25,40)(0,65)
\put(-4,58){\vector(2,3){5}}
\qbezier(40,5)(0,40)(40,65)
\put(36,58){\vector(2,3){5}}
\qbezier(200,5)(160,40)(200,65)
\put(196,58){\vector(2,3){5}}
\end{picture}
\end{center}
\caption{Representaci\'on gr\'afica de la estructura jer\'arquica del modelo general de probabilidad.}
\end{figure}
\\
.\\
\\
Es importante notar que la distribuci\'on de las variables latentes es arbitrario, por lo que con este modelo general de probabilidad resta determinar las distribuciones que mejor describan las caracter\'isticas de la relaci\'on entre las variables latentes. En la siguiente secci\'on se relizar\'a una comparaci\'on entre las distintas distribuciones que trabajar\'ian mejor con las caracter\'isticas particulares de los datos para su modelado.\\

\section{Construcci\'on del Modelo de Marcas}
Con el modelo general de probabilidad formulado en la secci\'on anterior se sientan las bases para hacer inferencia sobre duraci\'on y costos de padecimientos cr\'onico degenerativos. Igualmente, la determinaci\'on de las distribuciones de las variables latentes son cruciales para la predicci\'on sobre futuras observaciones.\\
\\
Seg\'un \cite{fader2013gamma} la distribuci\'on Gamma es muy \'util para modelar gastos en el campo actuarial, particularmente los siniestros. Esto es debido a que esta distribuci\'on tiene su soporte en los reales positivos, el sesgo a la derecha y las propiedades de las convoluciones que siguen los patrones de gasto si los siniestros se distribuyen Gamma. Aunado a esto, en una \'optica bayesiana, la distribuci\'on Gamma tiene muchas distribuciones conjugadas como la distribuci\'on Poisson, la distribuci\'on exponencial, la distribuci\'on normal con media conocida, la distribuci\'on Pareto entre otras; que ayudan a la linealidad del modelo general de probabilidad.\\
\\
Las duraciones se modelan mediante un modelo Gamma-Gamma, mientras que los costos con un modelo Gamma Inversa-Weibull. El modelo Gamma-Gamma de las duraciones se deriva del propio proceso de conteo que es una distribuci\'on conjugada.
\begin{align*}
P(d_{ij}|d_{ij-1})=\int P(d_{ij}|\theta_{ij}) P(\theta_{ij}|d_{ij-1})d\theta_{ij} \quad i \neq 1
\end{align*}
donde,
\begin{align*}
P(d|\theta) \sim Gamma(d|\alpha_d,\theta)\\
P(\theta) \sim Gamma(\theta|\alpha_{\theta},\beta_\theta)\\
\end{align*}
De manera an\'aloga, para los costos el modelo es Gamma Inversa-Weibull, la distribuci\'on Weibull es usada frecuentemente en el campo actuarial para modelar los siniestros, esto es porque al ser una distribuci\'on relacionada con la distribuci\'on exponencial, es \'util tambi\'en en la modelaci\'on de valores extremos. Por estas caracter\'isticas, la distribuci\'on Weibull es la que modelar\'a los costos en este trabajo, as\'i se asegura que si alguno de los costos del modelo llegara a diferir mucho del resto, el modelo tenga la flexibilidad para incluir los datos. Tomando en cuenta que los costos se modelan con la distribuci\'on Weibull, por conveniencia, la variable latente se distribuye Gamma Inversa.
\begin{align*}
P(c_{ij}|c_{ij-1})=\int P(c_{ij}|\gamma_{ij},d_{ij})P(\gamma_{ij}|d_{ij},c_{ij-1})d\gamma_{ij} \quad i \neq 1
\end{align*}
donde,
\begin{align*}
P(c|\gamma,d) \sim Weibull(c|d,\gamma)\\
P(\gamma) \sim Inv-Gamma(\gamma|\alpha_\gamma,\beta_\gamma)\\
\end{align*}
Con el modelo general de probabilidad y las distribuciones designadas ya es posible hacer inferencia sobre observaciones futuras, como se demostrar\'a en el siguiente cap\'itulo.
\section{Discusi\'on}
%?`Por qu\'e estos modelos son convenientes para modelar los costos de los padecimientos? Procesos Puntuales Marcados con Variables Latentes.\\
%\\
Los beneficios que presentan los modelos de procesos puntuales marcados con variables latentes para la estimaci\'on de costos totales de enfermedades cr\'onico-degenerativas son la flexibilidad que brindan para modelar las estructuras de dependencia entre las marcas y el proceso puntual. Es decir, que es un modelo construido de manera espec\'ifica para ajustarse a las trayectorias de cada paciente con un padecimiento cr\'onico degenerativo.\\
\\ 
La especificidad del modelo aunado a la estacionareidad asegurada por construcci\'on, se puede asegurar la inferencia de observaciones futuras. Aunque fuera del alcance de este proyecto de investigaci\'on, la inferencia es una herramienta poderosa para un estudio riguroso de tarificaci\'on en el sector asegurador para seguros de gastos m\'edicos mayores. La verosimilitud del modelo y la manera de hacer inferencia se desarrollar\'an a profundidad en el siguiente cap\'itulo, de acuerdo a las distribuciones designadas.